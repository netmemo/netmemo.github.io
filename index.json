[{"authors":["Noel"],"categories":["Automation"],"content":"https://www.terraform.io/docs/cli/commands/state/mv.html\nOn windows :\nterraform state mv nsxt_policy_security_policy.policy1 nsxt_policy_security_policy.policies[\\\u0026ldquo;policy1\\\u0026ldquo;]  It move resources from a construct like this\nlocals { policy1= { rule1 = { source = [\"src1\",\"src2\"] } } policy2 = { rule1 = { source = [\"src3\",\"src4\"] } } }  To a structure like this locals { policies = { policy1 = { rule1 = { source = [\"src1\",\"src2\"] } } policy2 = { rule2 = { source = [\"src3\",\"src4\"] } } } }  The main moving from resource \"nsxt_policy_security_policy\" \"policy1\"{ display_name = \"policy1\" category = \"Environment\" dynamic \"rule\" { for_each = local.policy1 content { source_groups = rule.value[\"sources\"] } } } resource \"nsxt_policy_security_policy\" \"policy2\"{ display_name = \"policy2\" category = \"Environment\" dynamic \"rule\" { for_each = local.policy2 content { source_groups = rule.value[\"sources\"] } } }  to resource \"nsxt_policy_security_policy\" \"policies\" { for_each = local.policies display_name = each.key category = \"Environment\" dynamic \"rule\" { for_each = each.value content { source_groups = rule.value[\"sources\"] } } }  The terraform state moving fromfrom 2 resources to 1 resource with 2 instances\nFrom { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;nsxt_policy_security_policy\u0026rdquo;, \u0026ldquo;name\u0026rdquo;: \u0026ldquo;policy1\u0026rdquo; \u0026ldquo;instances\u0026rdquo; : [ { \u0026hellip; } ] }, { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;nsxt_policy_security_policy\u0026rdquo;, \u0026ldquo;name\u0026rdquo;: \u0026ldquo;policy2\u0026rdquo; \u0026ldquo;instances\u0026rdquo; : [ { \u0026hellip; } ] }  To { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;nsxt_policy_security_policy\u0026rdquo;, \u0026ldquo;name\u0026rdquo;: \u0026ldquo;policies\u0026rdquo; \u0026ldquo;instances\u0026rdquo; : [ { \u0026ldquo;index_key\u0026rdquo;: \u0026ldquo;policy1\u0026rdquo; }, { \u0026ldquo;index_key\u0026rdquo;: \u0026ldquo;policy2\u0026rdquo; } ] } \n","date":1614286617,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614286617,"objectID":"e623927fcd938304d743d2b577f90d7b","permalink":"https://netmemo.github.io/post/terraform-refactoring-state-file/","publishdate":"2021-02-25T21:56:57+01:00","relpermalink":"/post/terraform-refactoring-state-file/","section":"post","summary":"https://www.terraform.io/docs/cli/commands/state/mv.html\nOn windows :\nterraform state mv nsxt_policy_security_policy.policy1 nsxt_policy_security_policy.policies[\\\u0026ldquo;policy1\\\u0026ldquo;]  It move resources from a construct like this\nlocals { policy1= { rule1 = { source = [\"src1\",\"src2\"] } } policy2 = { rule1 = { source = [\"src3\",\"src4\"] } } }  To a structure like this locals { policies = { policy1 = { rule1 = { source = [\"src1\",\"src2\"] } } policy2 = { rule2 = { source = [\"","tags":["Terraform","NSXT"],"title":"Terraform Refactoring State File","type":"post"},{"authors":["Noel"],"categories":["automation","developpment"],"content":"To install python packages offline (with no internet access), the simplest way is to dowload the packages with the dependencies on a server with internet access and the below command.\nC:\\Users\\Nono\\Desktop\\pythonpip download requests Collecting requests Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB) Collecting urllib3=1.21.1 Using cached urllib3-1.26.3-py2.py3-none-any.whl (137 kB) Collecting certifi=2017.4.17 Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB) Collecting idna=2.5 Using cached idna-2.10-py2.py3-none-any.whl (58 kB) Collecting chardet=3.0.2 Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB) Saved c:\\users\\nono\\desktop\\python\\requests-2.25.1-py2.py3-none-any.whl Saved c:\\users\\nono\\desktop\\python\\certifi-2020.12.5-py2.py3-none-any.whl Saved c:\\users\\nono\\desktop\\python\\chardet-4.0.0-py2.py3-none-any.whl Saved c:\\users\\nono\\desktop\\python\\idna-2.10-py2.py3-none-any.whl Saved c:\\users\\nono\\desktop\\python\\urllib3-1.26.3-py2.py3-none-any.whl Successfully downloaded requests certifi chardet idna urllib3  You then need to move all the files to the offline server in a directory and deploy the packages with the below command :\npip install --no-index --find-links=file:C:\\Users\\Nono2\\tools\\python-modules\\resquests requests Looking in links: file:///C:\\Users\\nboulene\\tools\\python-modules\\resquests Collecting requestsCollecting urllib3=1.21.1 (from requests) Collecting chardet=3.0.2 (from requests) Collecting idna=2.5 (from requests)Collecting certifi=2017.4.17 (from requests) Installing collected package: urllib3, chardet, idna, certifi, requests Successfully installed certifi-2020.12.5 chardet-4.0.0 idna-2.10 requests-2.25.1 urllib3-1.26.3  ","date":1614285974,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614285974,"objectID":"4c660db6d9b4ee7ceefaf6f85bae12f0","permalink":"https://netmemo.github.io/post/python-package-offline/","publishdate":"2021-02-25T21:46:14+01:00","relpermalink":"/post/python-package-offline/","section":"post","summary":"To install python packages offline (with no internet access), the simplest way is to dowload the packages with the dependencies on a server with internet access and the below command.\nC:\\Users\\Nono\\Desktop\\pythonpip download requests Collecting requests Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB) Collecting urllib3=1.21.1 Using cached urllib3-1.26.3-py2.py3-none-any.whl (137 kB) Collecting certifi=2017.4.17 Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB) Collecting idna=2.5 Using cached idna-2.10-py2.py3-none-any.whl (58 kB) Collecting chardet=3.0.2 Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB) Saved c:\\users\\nono\\desktop\\python\\requests-2.25.1-py2.py3-none-any.whl Saved c:\\users\\nono\\desktop\\python\\certifi-2020.","tags":["python"],"title":"Python Package Offline","type":"post"},{"authors":["Noel"],"categories":["Cisco","QOS"],"content":" QoS VOQ On N5K, In the case of unicast traffic, VOQ is an ingress buffer pool for 3 ingress port (1 ASIC). This buffer pool is split into n x reservable buffer of the size configured in the voq-limit command.If the ingress buffer is 16000 and the VOQ limit is 1024, that mean 16 flow can reserv buffers.When the shared buffer is exausted, the dedicated ingress buffer per port is used then when it\u0026rsquo;s full, the packet is droped.\nVOQ is reservable per egress port per class (pair).With small VOQ limit, there is lot of buffer available for non congested flow. With no VOQ limit, a congested port can use up to 50% of the total shared memory and those, 2 congested port can exaust all the ingress resources of an ASIC (3 ingress port) and drop can happen on this ASIC\nhttps://www.ciscolive.com/c/dam/r/ciscolive/us/docs/2015/pdf/BRKDCT-3100.pdf\nhttps://www.ciscolive.com/c/dam/r/ciscolive/us/docs/2017/pdf/BRKDCN-3346.pdf\nhttps://www.cisco.com/c/en/us/support/docs/switches/nexus-6000-series-switches/200401-Nexus-5600-6000-Understanding-and-Troub.html\nIn case of a Nexus 5600. 1 ASIC = 3 * 40Gb or 12*10G ports. Cells are the units in which buffers are allocated. One cell is 320 Bytes. ASIC Ingress buffer size : 48840 of available total cells (16M), shared among all 3x40Gb ports. Egress buffer is 9Mb (dedicated buffer per ASIC).\nVOQ. ingress per output port/class queues. E.g with 114 ports on the switch with 8 queues there would be 1152 VOQs.On N5600 Buffer can be shared accrod port and classes, giving more burst absorption capacity.\nDefault buffer allocation  minimum fixed buffer of 312 cells (100KB) is reserved per class (up to 8 classes) per ingress port, rest of the buffer is shared. This is done to guarantee minimum performance.\n  If there is only 1 class (the class-default for instance), there is only a single fixed/dedicated buffer per port.\n- 44,331 cells of shared buffer available for data traffic for all ports. shared buffer is used first.\n- any drop class can access half of the shared buffer- no-drop class (eg fcoe) can access complete shared buffer.\n- \u0026ldquo;queue-limit\u0026rdquo; under \u0026ldquo;network-qos\u0026rdquo; policy specifies the dedicated buffer for each port and each class. The dedicated buffer can be used by the port for only that class of service.\nvoq-limit Command \u0026ldquo;hardware unicast voq-limit [threshold \u0026hellip;]\u0026rdquo; enabling voq-limit turns on a shared buffer threshold per each voq.\nlimits the amount of buffers usable on the ingress interface, for packets headed towards a specific VoQ (\u0026ldquo;egress port, class\u0026rdquo; pair). Drops happens per VOQ, when its packet in ingress buffer exceed threshold: when the traffic ingress on a port and it consumes all 1024 cells, it will get dropped as discards.\nwhen the second flow traffic comes in, it will tage another 1024 cells as well but in a different VOQ and will not get dropped; this way voq thresholding prevents the non-congested egress port traffic drop.\nHOLD mitigation and VOQ thresholding Below is discussed for scenario without voq-limit enabledCongestion on one egress port in one CoS eventually bleeds into the congestion of its corresponding VOQ on the ingress port. Once the limit is reached then traffic gets dropped.\nOn N5600 ASIC Buffers are allocated per ingress port and are shared by all the egress ports that are seeing traffic from this ingressport.\nA stuck or slow-draining egress port can causse all buffers on one or more ingress ports that are senfing traffic to the egress port to be exhausted, thereby affecting all traffic on these ingress port. This is Head of Line Blocking (HOLB) problem.\nTo avoid this scenario, the VOQ for unicast traffic may be configured with a voq-limit threshold, at which point the port will stop accepting any more packets for congested destination (drops the packets or pauses the affected class for non-drop class type). When the queue length decrease and goes below another threshold, the VOQ starts accepting packets again.\nBy default VOQ Thresholding is disabled for all classes.\nQuestions  About the limit of 8000 cells, why not setting directly 16000 or removeing the limitation ?\n  Setting larger voq-limit increases the change to improve burst absorption but also leaves non-congested VOQs to be more likely affected by congested VOQs (as the latter can dip more into shared buffer).Disadvantage of having a voq-limit is that when we have a burst traffic comming in (like for distributed storage/VSAN), it connot use more than configured threshold of allocated cells and the bursty flow will have drops even though there is un-used ingress buffer.It\u0026rsquo;s recommanded to remove voq-limit in case of bursty traffic.\n Are the VoQ per UPC or per ingress interface ?\n  VOQs are per class per egress interface. E.g. With 114 ports on the switch with 8 queues there would be 1152 VOQs per port.If there is only 1 class (class-defauklt), the number of VOQ is matching the number of egress ports.\n Our undestanding is that if we remove the command voq limit, we might have HOLB while with the command it\u0026rsquo;s not possible. Could you explain how is this possible to have HOLD if VoQ is always used ?\n  This can happen because VOQ Thresholding (voq-limit) is not enabled by default. Therefore, each VOQ can borrow from shared buffer and some of non-congested VOQs would not be able to handle traffic due to lack of buffer space, even though they are not congested.\n Effect of changing or removing VOQ-limit on the traffic.\nThere would be subsecond traffic interruption on all ports.\n Effect of changing or removing VOQ-Limit on the FEX.\nThere should not be any effect on the FEX operation\n Could you describe the difference in the behavior of buffers (shared, ingress dedicated per port, voq per cos, drop) with the command voq limit default, with the command voq limit configured with the max value, and without the voq limit command ?\n  A. Without voq-limitShared - used by all ingress ports by default. 3*40G (or) 12*10G ports compete for usage, when per-port buffers are exhausted.Dedicated - samll, reserved per port per class. Can be adjusted with queue-limit command.VOQ drop thresholds are disabled.Shared is used first, only then overflow to dedicated.One drop class per ASIC can take up to half if the shared buffer.If congestion is constant, it can result in blocking for other VOQs in the same ingress port.Slow draining port can affect others by consuming shared and dedicated buffers.ExempleUnicast traffic coming on a 40G ingress port and egress port are 2x10G. When one of the egress port 10G is congested, it moght be possible that a new ingress flow from this 40G interface to another 10G interface can get affected as well because of non-availability of the ingress buffer.\nWhen the traffic ingress on a port it first fills the shared buffer. Each flow can take up ti 50% of the total shared buffer available (22200 cells or ~7.1MB). After filling 50% of the buffer the same flow will utilize the per-port fixed buffer.When the new flow comes ingress on that port, it tries to fill in the 50% of shared buffer but if shared and per-port buffer are already filled, this traffic would be dropped.We can avoir the new flow, that is goignt o different no-congested port, from getting dropped by enabling VOQ thresholding.\nB. With voq-limit default value 1024Drop happend per VOQ, each limited by 1024 cells.Congestion in one VOQ has minimal chances to affect other VOQsVOQ drop thresholds are minimal, so burst traffic flow coming in it cannot use more than 1024 allocated cells and will have drops even though there is un-used buffer.when the traffic ingress on a port consumes all 1024 cells, it will get dropped as discards.When the second flow traffic with destination to another egress port comes in, it may consume 1024 cells as well but a different VOQ- so will not get dropped.\nC. with voq-limit default value 16384drop happens per VOQ, each limited by 16384 cells.congestion in one VOQ does not affect other VOQs if there is enough shared buffer left.VOQ drop thresholds are at maximum.Burst traffic flow coming can use up to 16384 allocated cells and will have drop everything above it. Other VOQs buffering at the same instance can use remaining buffer (but nor more than 16384each). In theory, 3 VOQs, that are fully congested at the same time, could take all the buffer. It is very difficult to prefict instant buffer usage due to unpredictable nature of bursty flows, so exact values should be taken from production, e.g. Try with 16384 and reduce the threshold if negative impact is seen on non-congested flows.\nCouple of� solutions to resolve bursty trafic drop:  Remove VOQ limit completel (heavy burst trafic)\n Increase VOQ Threshold to 8000 or 16384 (max) and monitor the situation with discards=\u0026gt; show hardware profile buffer monitor interface ethernet\n Spread congested links betweek different ASICs.\n Implement policing of the traffic.\n  ","date":1614115484,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614115484,"objectID":"2c58fdeaa94f05a423d19179d5faeb30","permalink":"https://netmemo.github.io/post/n5600-buffering/","publishdate":"2021-02-23T22:24:44+01:00","relpermalink":"/post/n5600-buffering/","section":"post","summary":"QoS VOQ On N5K, In the case of unicast traffic, VOQ is an ingress buffer pool for 3 ingress port (1 ASIC). This buffer pool is split into n x reservable buffer of the size configured in the voq-limit command.If the ingress buffer is 16000 and the VOQ limit is 1024, that mean 16 flow can reserv buffers.When the shared buffer is exausted, the dedicated ingress buffer per port is used then when it\u0026rsquo;s full, the packet is droped.","tags":["Nexus","QOS","Buffering","Buffer","Cisco","N5600"],"title":"N5600 Buffering","type":"post"},{"authors":["Noel"],"categories":["Terraform"],"content":"The below post show how to create security policy groups for NSX-T with Terraform nested for_each loop and dynamic.\nThe variables are made from one map of list. Each list represent one group composed of tags.\nhttps://www.hashicorp.com/blog/hashicorp-terraform-0-12-preview-for-and-for-each\nvariable \u0026quot;mapgroups\u0026quot; { type = map default = { NBO = [\u0026quot;NBO\u0026quot;] NBO-PROD = [\u0026quot;NBO\u0026quot;,\u0026quot;PROD\u0026quot;] } } resource \u0026quot;nsxt_policy_group\u0026quot; \u0026quot;nbogroups\u0026quot; { for_each = var.mapgroups display_name = each.key criteria { dynamic \u0026quot;condition\u0026quot; { for_each = each.value content { key = \u0026quot;Tag\u0026quot; member_type = \u0026quot;VirtualMachine\u0026quot; operator = \u0026quot;EQUALS\u0026quot; value = condition.value } } } }  ","date":1613768810,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613768810,"objectID":"eea047d3620e58b7dcead6c5237d9a0f","permalink":"https://netmemo.github.io/post/tf-nsxt-nested-for-each/","publishdate":"2021-02-19T22:06:50+01:00","relpermalink":"/post/tf-nsxt-nested-for-each/","section":"post","summary":"The below post show how to create security policy groups for NSX-T with Terraform nested for_each loop and dynamic.\nThe variables are made from one map of list. Each list represent one group composed of tags.\nhttps://www.hashicorp.com/blog/hashicorp-terraform-0-12-preview-for-and-for-each\nvariable \u0026quot;mapgroups\u0026quot; { type = map default = { NBO = [\u0026quot;NBO\u0026quot;] NBO-PROD = [\u0026quot;NBO\u0026quot;,\u0026quot;PROD\u0026quot;] } } resource \u0026quot;nsxt_policy_group\u0026quot; \u0026quot;nbogroups\u0026quot; { for_each = var.mapgroups display_name = each.key criteria { dynamic \u0026quot;condition\u0026quot; { for_each = each.","tags":["Terraform","NSX-T"],"title":"Terraform nested for_each for NSX-T with dynamic","type":"post"},{"authors":["Noel"],"categories":["Terraform"],"content":" The below steps are what I did to create a terraform-bundle to use terraform with non default providers on a server that doesn\u0026rsquo;t have access to Internet. You can find the tool explanation in the below link.\nhttps://github.com/hashicorp/terraform/tree/master/tools/terraform-bundle\ninstallation of golang with msi downloaded here\nhttps://golang.org/doc/install\nClone the terraform repository to get the tool\nhttps://github.com/hashicorp/terraform.git\ncd terraform-master go install .\\tools\\terraform-bundle  Check the terraform version C:\\Users\\noyel\\Desktop\\tfforeach\\nsxt\u0026gt;terraform version Terraform v0.14.6 + provider registry.terraform.io/vmware/nsxt v3.0.1  Create a terraform-bundle.hcl file terraform { # Version of Terraform to include in the bundle. An exact version number # is required. version = \u0026quot;0.14.6\u0026quot; } # Define which provider plugins are to be included providers { # Include the newest \u0026quot;nsxt\u0026quot; provider version in the 1.0 series. nsxt = { source = \u0026quot;vmware/nsxt\u0026quot; versions = [\u0026quot;~\u0026gt; 3.0.0\u0026quot;] } }  Create the bundle C:\\Users\\noyel\\Desktop\\tfforeach\\nsxt\u0026gt;terraform-bundle package terraform-bundle.hcl Fetching Terraform 0.14.6 core package... Local plugin directory \u0026quot;.plugins\u0026quot; found; scanning for provider binaries. No \u0026quot;.plugins\u0026quot; directory found, skipping local provider discovery. - Finding vmware/nsxt versions matching \u0026quot;~\u0026gt; 3.0.0\u0026quot;... - Installing vmware/nsxt v3.0.1... Creating terraform_0.14.6-bundle2021021713_windows_amd64.zip ... All done!  Move the zip file to the server you want to use it. Unzip the file. For a basic utilization move the terraform.exe and plugins in the directory where your terraform files are.\nThe provider.tf file looks terraform { required_providers { nsxt = { source = \u0026quot;vmware/nsxt\u0026quot; version = \u0026quot;3.0.1\u0026quot; } } } provider \u0026quot;nsxt\u0026quot; { host = \u0026quot;1.2.3.4\u0026quot; username = \u0026quot;admin\u0026quot; password = \u0026quot;123\u0026quot; }  When initialize Terraform with the init command, specify the plugins directory.\nC:\\Users\\bubibi\\terraform\\terraform init -plugin-dir=C:\\Users\\bubibi\\terraform\\plugins Terraform has been successfuly initialized!  ","date":1613593957,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613593957,"objectID":"24ca96a911210aa9523b6b00f0ccd865","permalink":"https://netmemo.github.io/post/tf-bundle-windows/","publishdate":"2021-02-17T21:32:37+01:00","relpermalink":"/post/tf-bundle-windows/","section":"post","summary":"The below steps are what I did to create a terraform-bundle to use terraform with non default providers on a server that doesn\u0026rsquo;t have access to Internet. You can find the tool explanation in the below link.\nhttps://github.com/hashicorp/terraform/tree/master/tools/terraform-bundle\ninstallation of golang with msi downloaded here\nhttps://golang.org/doc/install\nClone the terraform repository to get the tool\nhttps://github.com/hashicorp/terraform.git\ncd terraform-master go install .\\tools\\terraform-bundle  Check the terraform version C:\\Users\\noyel\\Desktop\\tfforeach\\nsxt\u0026gt;terraform version Terraform v0.14.6 + provider registry.","tags":["Terraform","NSXT"],"title":"Create portable Terraform and plugins with Terraform-bundle for Windows","type":"post"},{"authors":["Noel"],"categories":["Terraform","AWS"],"content":" An extended explanation of the differences between for_each, for and count can be find on the below link\nhttps://blog.gruntwork.io/terraform-tips-tricks-loops-if-statements-and-gotchas-f739bbae55f9\nThe two main drawback of using count are :\n- Can\u0026rsquo;t be used to loop over inline blocks\n- Difficult to remove entry from a list because it change the index and those Terraform may want to destroy same resource with different index\nBelow are the an exemple of the variables used to create subnets within AWS VPCs and the main file with the for_each. The variables contain a map of subnets maps with cidr and az (availability zone) attributes. The for_each loop over the map of subnets maps to create the subnets.\nvariables.tf variable \u0026quot;tag_name\u0026quot; { default = \u0026quot;main-vpc\u0026quot; } variable \u0026quot;vpc-cidr\u0026quot; { default = \u0026quot;10.0.0.0/16\u0026quot; } variable \u0026quot;basename\u0026quot; { description = \u0026quot;Prefix used for all resources names\u0026quot; default = \u0026quot;nbo\u0026quot; } #map of maps for create subnets variable \u0026quot;prefix\u0026quot; { type = map default = { sub-1 = { az = \u0026quot;use2-az1\u0026quot; cidr = \u0026quot;10.0.198.0/24\u0026quot; } sub-2 = { az = \u0026quot;use2-az2\u0026quot; cidr = \u0026quot;10.0.199.0/24\u0026quot; } sub-3 = { az = \u0026quot;use2-az3\u0026quot; cidr = \u0026quot;10.0.200.0/24\u0026quot; } } }  main.tf resource \u0026quot;aws_vpc\u0026quot; \u0026quot;main-vpc\u0026quot; { cidr_block = var.vpc-cidr tags = { Name = var.tag_name } } resource \u0026quot;aws_subnet\u0026quot; \u0026quot;main-subnet\u0026quot; { for_each = var.prefix availability_zone_id = each.value[\u0026quot;az\u0026quot;] cidr_block = each.value[\u0026quot;cidr\u0026quot;] vpc_id = aws_vpc.main-vpc.id tags = { Name = \u0026quot;${var.basename}-subnet-${each.key}\u0026quot; } }  You can find the output of the terraform plan/apply, the terraform.state and the others tf files in the below links.\nhttps://github.com/netmemo/tf-for-each-exemple\n","date":1613591989,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613591989,"objectID":"fe57e5853341f40c14122a3e00179b87","permalink":"https://netmemo.github.io/post/tf-for-each/","publishdate":"2021-02-17T20:59:49+01:00","relpermalink":"/post/tf-for-each/","section":"post","summary":"An extended explanation of the differences between for_each, for and count can be find on the below link\nhttps://blog.gruntwork.io/terraform-tips-tricks-loops-if-statements-and-gotchas-f739bbae55f9\nThe two main drawback of using count are :\n- Can\u0026rsquo;t be used to loop over inline blocks\n- Difficult to remove entry from a list because it change the index and those Terraform may want to destroy same resource with different index\nBelow are the an exemple of the variables used to create subnets within AWS VPCs and the main file with the for_each.","tags":["Terraform","AWS"],"title":"Using Terraform for_each to create subnets in AWS VPC","type":"post"},{"authors":["Noel"],"categories":["Convergence"],"content":"One article that can help understanding and make decisions about fast failover https://blog.ipspace.net/2020/11/detecting-network-failure.html https://blog.ipspace.net/2012/09/do-we-need-lacp-and-udld.html\nIs there any benefit by enabling BFD on directly connected interface ?\nSometime it can be enabled to help veryfied that there are no issues on physical layer and data link layer of an interface. It can help if on the data link layer you are not using UDLD or LACP.\n","date":1606897790,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606897790,"objectID":"07b388783220f9b83a477257a4745a54","permalink":"https://netmemo.github.io/post/bfd-directly-connected/","publishdate":"2020-12-02T09:29:50+01:00","relpermalink":"/post/bfd-directly-connected/","section":"post","summary":"One article that can help understanding and make decisions about fast failover https://blog.ipspace.net/2020/11/detecting-network-failure.html https://blog.ipspace.net/2012/09/do-we-need-lacp-and-udld.html\nIs there any benefit by enabling BFD on directly connected interface ?\nSometime it can be enabled to help veryfied that there are no issues on physical layer and data link layer of an interface. It can help if on the data link layer you are not using UDLD or LACP.","tags":["BFD"],"title":"BFD on directly connected","type":"post"},{"authors":["Noel"],"categories":["DC"],"content":" \u0026ldquo;Several of these protocols are standards\u0026rdquo; My undestanding is that even if the protocols looks standard, Cisco did some modification on them : VXLAN (fiels to transport ACI Policies), ISIS (added the multidestination tree) and hence are note standard anymore.\n\u0026ldquo;Does it require proprietary server ?\u0026rdquo; Not prorietary servers but proprietary switches\u0026hellip;So you are locked in regarding the software and the hardware. Both can\u0026rsquo;t be decoupled. If you choose to move to another switch vendor, you need to change the hardware and sart learnong new software and protocols skills. Previously while you probably still need to change the softwar and the hardware, you didn\u0026rsquo;t need to learn everything from scratch regarding the protocols.\nIn the past with Fabric Path, I\u0026rsquo;ve already had issues by beeing locked-in with both. When Cisco will end up the support, you then need to change the hardware and learn new software/protocols skills.\nSecurity lock-in There is one more lock-in, this is regarding the security policies in ACI. If you use the Cisco Application Centric mode, it\u0026rsquo;s even worst, the day were Cisco will decide it\u0026rsquo;s not bankable anymore and start moving away from if, you will need to migrate the hardware, learn new software, new protocols and migrate the security to something completly different.\nFor certain organisation, that will be a nightmare and probably cost more money than investing regulary in people.\nIf you don\u0026rsquo;t want to use the Application Centric mode and just use the eNetwork Centruc mode, you still have an expensive solution with lot of options you will pay for but never use. Moreover you will inherit all the software complexity and associated bugs for features that are useless for you.\nSumm up Standard Protocols not so standard:\nISIS (Multidestination tree ftag)\nBGP for multi site\nVXLAN (Field to transport ACI policies)\nProprietary Protocols\nCOOP\nVery little public documentation\nLock in : Hardware, software, security\nPreviously : some features or knobs were proprietary or tie to hardware but not the all system\n=\u0026gt; EIGRP, software lock in but you can ignore it if you want\n=\u0026gt; FP at the time of the launch no other option were standard\nSoftware complexity due to all the feature you don\u0026rsquo;t want + software has been think to be application aware and even if you don\u0026rsquo;t want to use it, you will anyway inherit the code complexity of it.\nEverything centralise in a box right in the middle of the data path (Spine COOP devices).\nStopped product:\n  Loadbalancing : ACE/CSS   Fabric Path   Ironport ?   iWAN   VPn Concentrator  \nYou need EVPN anyway for multisite.\nYou need automation anyway because it\u0026rsquo;s too complex to manage via the GUI and you want to standardise all the conf.\n","date":1606587096,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606587096,"objectID":"5b1bcfa925458eb7f63027ca022c6cd1","permalink":"https://netmemo.github.io/post/aci-other-angle/","publishdate":"2020-11-28T19:11:36+01:00","relpermalink":"/post/aci-other-angle/","section":"post","summary":"\u0026ldquo;Several of these protocols are standards\u0026rdquo; My undestanding is that even if the protocols looks standard, Cisco did some modification on them : VXLAN (fiels to transport ACI Policies), ISIS (added the multidestination tree) and hence are note standard anymore.\n\u0026ldquo;Does it require proprietary server ?\u0026rdquo; Not prorietary servers but proprietary switches\u0026hellip;So you are locked in regarding the software and the hardware. Both can\u0026rsquo;t be decoupled. If you choose to move to another switch vendor, you need to change the hardware and sart learnong new software and protocols skills.","tags":["ACI","DC"],"title":"ACI from an other angle","type":"post"},{"authors":["Noel"],"categories":["SP"],"content":" ISIS Segment routing basics for Arista EOS References:\nhttps://www.arista.com/en/um-eos/eos-section-35-3-is-is-segment-routing\nSRGB Segment Routing Golbal Block\nPrefix-SID It\u0026rsquo;s global and unique. It identify a prefix. It\u0026rsquo;s called anycast SID when it\u0026rsquo;s send by a group of router.\nNode-SID It\u0026rsquo;s global and unique. Only one per node. It identify the node.\nAdjacent-SID It\u0026rsquo;s local and can use a dynamique range. It\u0026rsquo;s used to identify an interconnection between 2 nodes.\nWith Arista EOS 4.23 it\u0026rsquo;s automaticaly allocated from the isis dynamic range show mpls label ranges.\nBasic config for ARISTA I have added the prefix-sid to test it end to end between the VPC but actually it can work without the prefix-sid. In the next article I will add the L3 VPN on top of SR without using prefix-sid In bold you find the ISIS-SR specific command require to enable ISIS-SR\nR1 interface Loopback1 ip address 1.1.1.1/32 node-segment ipv4 index 1 isis enable ISIS-SR ! interface Ethernet1 no switchport ip address 10.10.12.1/24 isis enable ISIS-SR ! interface Ethernet2 no switchport ip address 10.10.10.1/24 isis enable ISIS-SR ! ip routing ! mpls ip ! router isis ISIS-SR net 10.0000.0010.0100.1001.00 is-type level-2 ! address-family ipv4 unicast ! segment-routing mpls  no shutdown prefix-segment 10.10.10.0/24 index 51 !  R2 interface Loopback1 ip address 2.2.2.2/32 node-segment ipv4 index 2 isis enable ISIS-SR ! interface Ethernet1 no switchport ip address 10.10.12.2/24 isis enable ISIS-SR ! interface Ethernet2 no switchport ip address 10.10.23.2/24 isis enable ISIS-SR ! ip routing ! mpls ip ! router isis ISIS-SR net 10.0000.0020.0200.2002.00 is-type level-2 ! address-family ipv4 unicast ! segment-routing mpls no shutdown !  R3 interface Loopback1 ip address 3.3.3.3/32 node-segment ipv4 index 3 isis enable ISIS-SR ! interface Ethernet1 no switchport ip address 10.10.23.3/24 isis enable ISIS-SR ! interface Ethernet2 no switchport ip address 10.10.30.1/24 isis enable ISIS-SR ! ip routing ! mpls ip ! router isis ISIS-SR net 10.0000.0030.0300.3003.00 is-type level-2 ! address-family ipv4 unicast ! segment-routing mpls no shutdown prefix-segment 10.10.30.0/24 index 53 !  show commands R1#show isis segment-routing System ID: R1 Instance: ISIS-SR SR supported Data-plane: MPLS SR Router ID: 1.1.1.1 SR Global Block( SRGB ): Base: 900000 Size: 65536 Adj-SID allocation mode: SR-adjacencies Adj-SID allocation pool: Base: 100000 Size: 16384 All Prefix Segments have : P:0 E:0 V:0 L:0 IS-IS Reachability Algorithm : SPF (0) Number of IS-IS segment routing capable peers: 2 Self-Originated Segment Statistics: Node-Segments : 1 Prefix-Segments : 1 Proxy-Node-Segments : 0 Adjacency Segments : 1  R1#show mpls segment-routing bindings 1.1.1.1/32 Local binding: Label: imp-null Remote binding: Peer ID: 0020.0200.2002, Label: 900001 2.2.2.2/32 Local binding: Label: 900002 Remote binding: Peer ID: 0020.0200.2002, Label: imp-null 3.3.3.3/32 Local binding: Label: 900003 Remote binding: Peer ID: 0020.0200.2002, Label: 900003 10.10.10.0/24 Local binding: Label: imp-null Remote binding: Peer ID: 0020.0200.2002, Label: 900051 10.10.30.0/24 Local binding: Label: 900053 Remote binding: Peer ID: 0020.0200.2002, Label: 900053  R1#show isis segment-routing prefix-segments System ID: 0010.0100.1001 Instance: 'ISIS-SR' SR supported Data-plane: MPLS SR Router ID: 1.1.1.1 Node: 3 Proxy-Node: 0 Prefix: 2 Total Segments: 5 Flag Descriptions: R: Re-advertised, N: Node Segment, P: no-PHP E: Explicit-NULL, V: Value, L: Local Segment status codes: * - Self originated Prefix, L1 - level 1, L2 - level 2 Prefix SID Type Flags System ID Level Protection ------------------------- ----- ---------- ----------------------- --------------- ----- ---------- * 1.1.1.1/32 1 Node R:0 N:1 P:0 E:0 V:0 L:0 0010.0100.1001 L2 unprotected 2.2.2.2/32 2 Node R:0 N:1 P:0 E:0 V:0 L:0 0020.0200.2002 L2 unprotected 3.3.3.3/32 3 Node R:0 N:1 P:0 E:0 V:0 L:0 0030.0300.3003 L2 unprotected * 10.10.10.0/24 51 Prefix R:0 N:0 P:0 E:0 V:0 L:0 0010.0100.1001 L2 unprotected 10.10.30.0/24 53 Prefix R:0 N:0 P:0 E:0 V:0 L:0 0030.0300.3003 L2 unprotected  R1#show isis segment-routing adjacency-segments System ID: R1 Instance: ISIS-SR SR supported Data-plane: MPLS SR Router ID: 1.1.1.1 Adj-SID allocation mode: SR-adjacencies Adj-SID allocation pool: Base: 100000 Size: 16384 Adjacency Segment Count: 1 Flag Descriptions: F: Ipv6 address family, B: Backup, V: Value L: Local, S: Set Segment Status codes: L1 - Level-1 adjacency, L2 - Level-2 adjacency, P2P - Point-to-Point adjacency, LAN - Broadcast adjacency Locally Originated Adjacency Segments Adj IP Address Local Intf SID SID Source Flags Type --------------- ----------- ------- ------------ --------------------- -------- 10.10.12.2 Et1 100000 Dynamic F:0 B:0 V:1 L:1 S:0 LAN L2 Protection ----------- unprotected  ","date":1606237925,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606237925,"objectID":"39ad9fd59aab0ba8ffe0b924874c0c4c","permalink":"https://netmemo.github.io/post/aristabasesr/","publishdate":"2020-11-24T18:12:05+01:00","relpermalink":"/post/aristabasesr/","section":"post","summary":"ISIS Segment routing basics for Arista EOS References:\nhttps://www.arista.com/en/um-eos/eos-section-35-3-is-is-segment-routing\nSRGB Segment Routing Golbal Block\nPrefix-SID It\u0026rsquo;s global and unique. It identify a prefix. It\u0026rsquo;s called anycast SID when it\u0026rsquo;s send by a group of router.\nNode-SID It\u0026rsquo;s global and unique. Only one per node. It identify the node.\nAdjacent-SID It\u0026rsquo;s local and can use a dynamique range. It\u0026rsquo;s used to identify an interconnection between 2 nodes.\nWith Arista EOS 4.","tags":["SR","Segment Routing","Arista","EOS","ISIS"],"title":"Arista basic ISIS-SR","type":"post"},{"authors":[],"categories":[],"content":" Maximum path In the RIB + FIB ECMP (multipath)\nIs PIC supported by default ?\nhttps://www.cisco.com/c/en/us/td/docs/ios-xml/ios/iproute_bgp/configuration/xe-3s/irg-xe-3s-book/irg-bgp-mp-pic.html\n=\u0026gt; With BGP Multipath, the BGP prefix-independant convergence (PIC) feature is supported\n Attribut that should be identical \n- Weight\n- LP\n- AS Path (AS Number unless relax us used, AS length)\n- Origin Code\n- MED\n- IGP Metric Next hop should be different\nAdd Path If the path are equal, allow to advertise more than one bes oath (need to test in eBGP).\nMostly used with BGP without MPLS. If MPLS is used it\u0026rsquo;s better to have an RD different for each VRF of each router (easier to troubleshoot).\nhttps://orhanergun.net/wp-content/uploads/2019/11/BGP-Add-path-vs-Shadow-RR-vs-Shadow-Session-vs-Unique-RD.pdf\nPIC https://www.ciscolive.com/c/dam/r/ciscolive/us/docs/2016/pdf/BRKRST-3321.pdf I don\u0026rsquo;t neded it at the moment because we don\u0026rsquo;t need this level if convergence (couple of minutes vs ms if you have hundres of thousand of prefixes)\nhttps://blog.ipspace.net/2012/01/prefix-independent-convergence-pic.html\nThe generic optimization of the RIB-to-FIB update process is known as Prefix-Independent Convergence (PIC) - if the routing protocols can pre-compute alternate paths, suitably designed FIB can use that information to cache alternate next hops. Updating such a FIB no longer involves numerous updates to individual prefixes; you have to change only the next hop reachability information.\nBest External Allow a router to advertise it\u0026rsquo;s best external path even if in it\u0026rsquo;s BGP table it does have a beter route from inside\nLABEL ALLOCATION Per VRF  Cons \n- IP Lookup needed after label lookup (can be a benefit, cf route sum issue)\n- No granular load balancing because the bottom label is the same for all prefixes, if platform load balances on bottom label\n- Potential forwarding loop during local traffic diversion to support PIC (Transient loop)\n- No support for EIBGP multipath\n Pros \n- 1 label per vrf (less label used)\nPer CE  Cons \n- No granular load balancing because the bottom label is the same for all prefixes from one CE, if platform load balances on bottom label\n- eBGPload balancing \u0026amp; BGP PIC is not supported (it makes usage of label diversity), unless resilient per-ce label\n- Only single hop eBGPsupported, no multihop\n Pros \n- No IP lookup needed after label lookup\n- Per-CE : one MPLS label per next-hop (so per connected CE router)(Number of MPLS labels used is very low)\n","date":1589176941,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589176941,"objectID":"b539297dbff77ad990caec0ccd889e01","permalink":"https://netmemo.github.io/post/bgp-multipath/","publishdate":"2020-05-11T08:02:21+02:00","relpermalink":"/post/bgp-multipath/","section":"post","summary":"Maximum path In the RIB + FIB ECMP (multipath)\nIs PIC supported by default ?\nhttps://www.cisco.com/c/en/us/td/docs/ios-xml/ios/iproute_bgp/configuration/xe-3s/irg-xe-3s-book/irg-bgp-mp-pic.html\n=\u0026gt; With BGP Multipath, the BGP prefix-independant convergence (PIC) feature is supported\n Attribut that should be identical \n- Weight\n- LP\n- AS Path (AS Number unless relax us used, AS length)\n- Origin Code\n- MED\n- IGP Metric Next hop should be different\nAdd Path If the path are equal, allow to advertise more than one bes oath (need to test in eBGP).","tags":[],"title":"Bgp Multipath","type":"post"},{"authors":["Noel"],"categories":["ROUTING"],"content":"prerequis : - github desktop - hugo\nconfig.toml =\u0026gt; need to be modify to change the copyright date\nlancer cmd\nGo to the folder blog : C:\\Users\\noyel\\Documents\\Site\\blog\u0026gt;\ntaper : hugo new post/my-first-post.md\ntry the web site with : hugo server -D\nentrer http://localhost:1313/\ngenerate the web site with : hugo -t \u0026ldquo;academic\u0026rdquo; Move the content of the folder C:\\Users\\noyel\\Documents\\Site\\blog\\public\nin GitHub\\netmemo.github.io lancer github desktop, commit/push to master\nTo have a file attached for the post, create a directory with the exact same name as the post md file.\nThe language used to write a blog post is Markdown https://www.markdownguide.org/basic-syntax https://www.tutorialspoint.com/html/html_ascii_codes.htm\nBold and underline **\u0026lt;ins\u0026gt; Cons \u0026lt;/ins\u0026gt;**\n","date":1589176811,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589176811,"objectID":"b574d36d30607eb31ef58b610a3fbd9a","permalink":"https://netmemo.github.io/post/how-to-hugo/","publishdate":"2020-05-11T08:00:11+02:00","relpermalink":"/post/how-to-hugo/","section":"post","summary":"prerequis : - github desktop - hugo\nconfig.toml =\u0026gt; need to be modify to change the copyright date\nlancer cmd\nGo to the folder blog : C:\\Users\\noyel\\Documents\\Site\\blog\u0026gt;\ntaper : hugo new post/my-first-post.md\ntry the web site with : hugo server -D\nentrer http://localhost:1313/\ngenerate the web site with : hugo -t \u0026ldquo;academic\u0026rdquo; Move the content of the folder C:\\Users\\noyel\\Documents\\Site\\blog\\public\nin GitHub\\netmemo.github.io lancer github desktop, commit/push to master\nTo have a file attached for the post, create a directory with the exact same name as the post md file.","tags":["ANYCAST","OSPF","BGP","ROUTING"],"title":"How to hugo","type":"post"},{"authors":["Noel"],"categories":["ROUTING"],"content":" Issue R3 route traffic to R4 instead of R1. Route 10.10.10.10 toward the WAN is prefered instead of the OSPF LAN DC route. DC Client that try to reach the DC\u0026rsquo;s 10.10.10.10 address are routed toward the WAN\nWhy R3 is installing in it RIB and redistributing the wrong routes 10.10.10.10 because it does have a better AD 20.\nWorkarround  If we filter the redistribution that doesn\u0026rsquo;t help because when the packet arrive to R3 he will still prefer the BGP route. If we drop the prefix on R3 we loose the redundancy Increase the AD of the WAN route on R3  ","date":1582065947,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582065947,"objectID":"cbd0cba140a1956254039ffbd8bdf2a3","permalink":"https://netmemo.github.io/post/ospfbgpanycast/","publishdate":"2020-02-18T23:45:47+01:00","relpermalink":"/post/ospfbgpanycast/","section":"post","summary":"Issue R3 route traffic to R4 instead of R1. Route 10.10.10.10 toward the WAN is prefered instead of the OSPF LAN DC route. DC Client that try to reach the DC\u0026rsquo;s 10.10.10.10 address are routed toward the WAN\nWhy R3 is installing in it RIB and redistributing the wrong routes 10.10.10.10 because it does have a better AD 20.\nWorkarround  If we filter the redistribution that doesn\u0026rsquo;t help because when the packet arrive to R3 he will still prefer the BGP route.","tags":["ANYCAST","OSPF","BGP","ROUTING"],"title":"OSPF vs BGP with anycast prefix","type":"post"},{"authors":["Noel"],"categories":["DNS","loadbalancing"],"content":" DNS Steps to resolve a web site url in IP : !! The CNAME is normally not allowed at the apex, so I need to find another way) !! The following steps are when nothing is yet cached in any servers. This use case is for a recusive DNS resolver.\n The user try to access www.toto.com from his browser. His computer send the DNS query to the system\u0026#39;s configured DNS Resolver. For instance 9.9.9.9 (quad9).\n The recursive (not iterative) DNS resolver send the DNS query to one of the 13 root servers to know how to resovle \u0026ldquo;.com\u0026rdquo; The root servers are know by default by all resolvers.\n The root server answer with a referral to the TLD server for \u0026ldquo;.com\u0026rdquo;\n The DNS resolver query the TLD to know who is in charge for resolving \u0026ldquo;toto.com\u0026rdquo;\n The TLD server answer with the glue records configured by the website owner through the registrar portal.\n The DNS resolver query Authoritative DNS server of the company for the IP address of \u0026ldquo;www.toto.com\u0026rdquo;\n The Authoritative DNS Server of the company answer with a CNAME of www.gslb.toto.com and the IP address of the GSLB NS in charge of the web site.\n The resolver query the GSLB to have the IP address of \u0026ldquo;www.gslb.toto.com\u0026rdquo;\n The GSLB answer with the IP address of the loadbalancer in charge of the IP address of the web site.\n The DNS Resolver forward the answer to the user.\n The user web browser can directly access the IP address of the web site.\n    1. This blog was mostly inspired from https://www.cloudflare.com/learning/dns/dns-server-types/ \u0026gt; \n 2. This link might help regarding the TTL https://www.bortzmeyer.org/forcer-ttl.html \n ","date":1570224048,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570224048,"objectID":"66e3bae2e78e657498a689fbbf5a44cf","permalink":"https://netmemo.github.io/post/dns-one-design/","publishdate":"2019-10-04T23:20:48+02:00","relpermalink":"/post/dns-one-design/","section":"post","summary":"DNS Steps to resolve a web site url in IP : !! The CNAME is normally not allowed at the apex, so I need to find another way) !! The following steps are when nothing is yet cached in any servers. This use case is for a recusive DNS resolver.\n The user try to access www.toto.com from his browser. His computer send the DNS query to the system\u0026#39;s configured DNS Resolver.","tags":["DNS","GSLB","GTM","LTM","loadbalancer","Loadbalancing","DNSTTL"],"title":"One of many possible DNS Design (Work in progress)","type":"post"},{"authors":["Noel"],"categories":["DNS"],"content":"At every layer, local cache of servers can override the configured TTL even if the TTL override is breaking the RFC\nCascade of DNS TTL of the wrong information make the information last longer in caches .\n","date":1570223703,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570223703,"objectID":"ab34344ddda45c0fa8882c84fd34f428","permalink":"https://netmemo.github.io/post/dns-ttl-cascade/","publishdate":"2019-10-04T23:15:03+02:00","relpermalink":"/post/dns-ttl-cascade/","section":"post","summary":"At every layer, local cache of servers can override the configured TTL even if the TTL override is breaking the RFC\nCascade of DNS TTL of the wrong information make the information last longer in caches .","tags":["DNS","DNSTTL","DNS_CACHE"],"title":"Dns Ttl Cascade (Work in progress)","type":"post"},{"authors":["Noel"],"categories":["DNS","loadbalancing"],"content":" For a short A record TTL Client keep using A until TTL has expired. If A is 30 second and outage occure just after the DNS request for A record, the outage last 30 seconds.\nWen A has expired, the client browser query the resolver who might query the GSLB NS of the broken site, wait for the DNS query timeout then query the working GSLB NS that will return the working A record. As the A TTL is short, the client might experience lots of DNS query timeout (every 30seconds when it will query for the A record to the broken GSLB NS) that might impact the browsing experience and slow it down.\nFor a longer A record TTL Client keep using A until TTL has expired. If A is 10mn and outage occure just after the DNS request for A, the outage last 10mn.\nWhen A has expired, the client browser query the resolver who might query the GSLB NS of the broken site for the A record, wait for the DNS query timeout then query the working GSLB NS that will return the working A record. As the A TTL is long, the initial outage might be up to 10mn but the subsequents DNS request will experience less DNS request timeout toward the broken GSLB IPs. After the potential initial 10mn outage, the browsing experience under GSLB failure might be slightly better. In the end, the GSLB will have less DNS request to handle even during normal operation.\n  1. This blog was mostly inspired from https://www.cloudflare.com/learning/dns/dns-server-types/ \u0026gt; \n 2. This link might help regarding the TTL https://www.bortzmeyer.org/forcer-ttl.html \n ","date":1556399167,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556399167,"objectID":"bbb77c6e22aace3868481e8826e60233","permalink":"https://netmemo.github.io/post/dns-outage/","publishdate":"2019-04-27T23:06:07+02:00","relpermalink":"/post/dns-outage/","section":"post","summary":"For a short A record TTL Client keep using A until TTL has expired. If A is 30 second and outage occure just after the DNS request for A record, the outage last 30 seconds.\nWen A has expired, the client browser query the resolver who might query the GSLB NS of the broken site, wait for the DNS query timeout then query the working GSLB NS that will return the working A record.","tags":["DNS","GSLB","GTM","LTM","loadbalancer","Loadbalancing","DNSTTL"],"title":"Dns Outage (Work in progress)","type":"post"},{"authors":["Noel"],"categories":["tools"],"content":" Below is a very light virtual machine based on Core Linux kernel 4.8 (TinyCore) 26 Mo with network tools like iperf3, tcpdump, net-bridging, iproute2, busybox (httpd), tcpreplay, nmap, openssh.\ncorelinux1.5.ova\nbasic commands/directory /etc/sysconfig/tcedir/optional =\u0026gt; packages /etc/sysconfig/tcedir/onboot.lst =\u0026gt; on boot package to be loaded  sudo vi /opt/eth0.sh =\u0026gt; change interfaces parameters #configure an interface pkill udhcp =\u0026gt; stop dhcp for this interface ifconfig eth1 10.253.106.2 netmask 255.255.255.192 up route add default gw 10.253.106.1  filetool.sh -b =\u0026gt; save the configuration changes  vi /opt/hostnameAuto.sh =\u0026gt; change the hostname vi /opt/bootlocal.sh =\u0026gt; the script that is executed after the device has booted.  ","date":1540215355,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540215355,"objectID":"e1a31189949599c96ef2ff11865654fa","permalink":"https://netmemo.github.io/post/corelinuxnetmemo/","publishdate":"2018-10-22T15:35:55+02:00","relpermalink":"/post/corelinuxnetmemo/","section":"post","summary":"Below is a very light virtual machine based on Core Linux kernel 4.8 (TinyCore) 26 Mo with network tools like iperf3, tcpdump, net-bridging, iproute2, busybox (httpd), tcpreplay, nmap, openssh.\ncorelinux1.5.ova\nbasic commands/directory /etc/sysconfig/tcedir/optional =\u0026gt; packages /etc/sysconfig/tcedir/onboot.lst =\u0026gt; on boot package to be loaded  sudo vi /opt/eth0.sh =\u0026gt; change interfaces parameters #configure an interface pkill udhcp =\u0026gt; stop dhcp for this interface ifconfig eth1 10.253.106.2 netmask 255.255.255.192 up route add default gw 10.","tags":["tools","VM","Core Linux"],"title":"Core Linux Netmemo","type":"post"},{"authors":["Noel"],"categories":["container"],"content":" This post is a memo on how I did the installtion of Kubernetes and Calico on VMs. It\u0026rsquo;s not some best pactrices in anyway.\nI\u0026rsquo;ve chose VM because I didn\u0026rsquo;t want to depend on any Cloud infrastructure. I\u0026rsquo;ve also wanted to understand the network interaction between K8s parts from an infrastructure point of view.\nPrerequisite : know how to create VMs on any hypervisors\nSteps to deploy K8s :  Install 1 ubuntu router with 3 interfaces. 1 for NAT/Internet access and 2 for the K8s LAN. I\u0026rsquo;ve created 2 LAN to see what happen under the hood when K8s nodes communicates.\n Install 3 Ubuntu servers, 1 for the master and 2 for the workers. 1 worker in the same ethernet segment and subnet than the master. 1 worker in another network.\n Gotchas:  By default, the K8s interface is the one with the default route. All my servers have one OOB interface and one production interface. Special tunning for k8s =\u0026gt; turn off the swap   Install runtime and enable it on boot\n Installing kubeadm, kubelet and kubectl\n Initializing the master (choose the pod network add-on before to add the relevent parameters, Calico parameters in my case)\n Install the pod network add-on\n Join node/workers to the cluster\n That it, you can now play with the K8s cluster\n  Optional : Install ctl for calico\nComments : To create anything you just have to kubectl apply -f myfile The magic happen in myfile where you describe what you want to create.\nBelow the capture after the lab is completed CaptureCalicok8s\nDetails of the tasks 3. https://kubernetes.io/docs/setup/independent/install-kubeadm/#installing-runtime\nI\u0026rsquo;ve needed to add the following commands\nsystemctl enable docker.service systemctl start docker.service  4. https://kubernetes.io/docs/setup/independent/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl\napt-get update \u0026amp;amp;\u0026amp;amp; apt-get install -y apt-transport-https curl curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - cat \u0026amp;lt;\u0026amp;lt;EOF \u0026amp;gt;/etc/apt/sources.list.d/kubernetes.list deb http://apt.kubernetes.io/ kubernetes-xenial main EOF apt-get update apt-get install -y kubelet kubeadm kubectl apt-mark hold kubelet kubeadm kubectl  5.\nkubeadm init --pod-network-cidr=192.168.0.0/16 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config  6.\nkubectl apply -f https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml kubectl apply -f https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml  7.\nkubeadm join 10.0.1.10:6443 --token d34b9i.v03t2yiozio63cq6 --discovery-token-ca-cert-hash sha256:c21d04ea23790a0bf81cf64118e3a9075ffb63ed90bc697acef5793386e9eb16  ","date":1538776759,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538776759,"objectID":"04e4be9702fa5b85a26f6612d64762cc","permalink":"https://netmemo.github.io/post/k8s-on-vms-with-calico/","publishdate":"2018-10-05T23:59:19+02:00","relpermalink":"/post/k8s-on-vms-with-calico/","section":"post","summary":"This post is a memo on how I did the installtion of Kubernetes and Calico on VMs. It\u0026rsquo;s not some best pactrices in anyway.\nI\u0026rsquo;ve chose VM because I didn\u0026rsquo;t want to depend on any Cloud infrastructure. I\u0026rsquo;ve also wanted to understand the network interaction between K8s parts from an infrastructure point of view.\nPrerequisite : know how to create VMs on any hypervisors\nSteps to deploy K8s :  Install 1 ubuntu router with 3 interfaces.","tags":["calico","docker","k8s","kubernetes","netplan","ubuntu","virtualbox"],"title":"K8s on Vms With Calico","type":"post"},{"authors":["Noel"],"categories":["cisco","nexus"],"content":"On N7K\nhttps://www.cisco.com/c/en/us/support/docs/switches/nexus-7000-series-switches/116647-technote-product-00.html\n=\u0026gt; flanker car avec la commande show hardware internal dev-port-map, il n\u0026rsquo;y a pas d\u0026rsquo;asic Clipper, uniquement des flanker\nSample of icmp troubleshooting from the Admin VDC\nshow module attach module 1 show hardware internal dev-port-map elam asic flanker instance 2 layer2 trigger dbus ipv4 egress if destination-ipv4-address 10.253.108.90 start status  elam asic flanker instance 2 layer2 trigger dbus ipv4 ingress if destination-ipv4-address 10.253.108.90 start status  On N5K\nhttps://www.cisco.com/c/en/us/support/docs/switches/nexus-6000-series-switches/118902-technote-nexus-00.html\nMY-SWITCH# show platform fwm info pif ethernet 2/2 | inc slot_asic Eth2/2 pd: slot 1 logical port num 1 slot_asic_num 0 global_asic_num 5 fw_inst 4 phy_fw_inst 1 fc 0  Note: The slot numbers are 0-based, whereas the bigsur instances are 1-based. Therefore, in this example slot 1 corresponds to bigsur instance 2.\n=\u0026gt; slot 1 become 2 in the elam command, the instance stay the same as the slot_asic_num =\u0026gt; ingress for the traffic ingressing the interface, egress for the egressing traffic.\nelam slot 2 asic bigsur instance 0 trigger lu ingress ipv4 if source-ipv4-address_ipv4 10.253.108.226 destination-ipv4-address_ipv4 10.253.108.90 start capture show elam asic bigsur show capture lu stop capture  ","date":1538606937,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538606937,"objectID":"f8fba9a12db76da45dc28dbce3e682ba","permalink":"https://netmemo.github.io/post/troubleshooting-elam-cisco-n7k-n5k/","publishdate":"2018-10-04T00:48:57+02:00","relpermalink":"/post/troubleshooting-elam-cisco-n7k-n5k/","section":"post","summary":"On N7K\nhttps://www.cisco.com/c/en/us/support/docs/switches/nexus-7000-series-switches/116647-technote-product-00.html\n=\u0026gt; flanker car avec la commande show hardware internal dev-port-map, il n\u0026rsquo;y a pas d\u0026rsquo;asic Clipper, uniquement des flanker\nSample of icmp troubleshooting from the Admin VDC\nshow module attach module 1 show hardware internal dev-port-map elam asic flanker instance 2 layer2 trigger dbus ipv4 egress if destination-ipv4-address 10.253.108.90 start status  elam asic flanker instance 2 layer2 trigger dbus ipv4 ingress if destination-ipv4-address 10.253.108.90 start status  On N5K","tags":["cisco","elam","N5K","N7K","troubleshooting"],"title":"Troubleshooting Elam Cisco N7k N5k","type":"post"},{"authors":["Noel"],"categories":["container"],"content":"This is the cheat sheet for the post : https://netmemo.github.io/post/k8s-on-vms-with-calico/\nThe following post contain raw entry only for reminder purpose.\nBellow are the links I\u0026rsquo;ve used to understand/did my lab\nhttps://fr.wikipedia.org/wiki/Kubernetes#/media/File:Kubernetes.png https://kubernetes.io/docs/setup/independent/install-kubeadm/ https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/ https://kubernetes.io/docs/tutorials/k8s101/ https://kubernetes.io/docs/tutorials/k8s201/ https://kubernetes.io/docs/reference/kubectl/cheatsheet/\nJoin a node/worker to the master\nkubeadm join 10.0.1.10:6443 --token d34b9i.v03t2yiozio63cq6 --discovery-token-ca-cert-hash sha256:c21d04ea23790a0bf81cf64118e3a9075ffb63ed90bc697acef5793386e9eb16  Delete a deployment\nkubectl delete deployment nginx-deployment-nbo  To get the logs of a specific container. -n is to specify the namespace\nkubectl logs calico-node-zxvjv -n kube-system calico-node  Allow to launch a shell for a specific container\nkubectl exec -it nginx-deployment-nbo-fd57b7b88-l8xsv -- /bin/bash  Create a static page in the container to differentiate it from the others. The -c option is to ask bash to execute the command.\nkubectl exec -it nginx-deployment-nbo-fd57b7b88-kkw9s -- /bin/bash -c \u0026quot;echo Hello shell demo SRV1 \u0026gt; /usr/share/nginx/html/index.html\u0026quot; kubectl exec -it nginx-deployment-nbo-fd57b7b88-kkw9s cat /usr/share/nginx/html/index.html  To troubleshhot\njournalctl -r  Display all pods, even with the system name space, -o wide allow to see the IP addresses\nkubectl get pods --all-namespaces -o wide  To see the last messages of container associated to the pode\nkubectl describe pod -n kube-system calico-node-zxvjv  Allow to see the node/server/worker ip addresses (-o wide)\nsudo kubectl get node -o wide  by default kubernetes don\u0026rsquo;t work with swap, so I needed to disable it with the command swapoff and to comment the swap line in the fstab file.\nswapoff vi /etc/fstab # /etc/fstab: static file system information. # # Use 'blkid' to print the universally unique identifier for a # device; this may be used with UUID= as a more robust way to name devices # that works even if disks are added and removed. See fstab(5). # # /dev/mapper/ubuntu--srv--base--vg-root / ext4 errors=remount-ro 0 1 #/dev/mapper/ubuntu--srv--base--vg-swap_1 none swap sw 0 0  Not related to Kubernets but you need to modify the interfaces\nvi /etc/netplan/01-netcfg.yaml  Add interfaces to ubuntu\n/etc/netplan/01-netcfg.yaml  This file describes the network interfaces available on your system For more information, see netplan(5).\nnetwork: version: 2 renderer: networkd ethernets: enp0s3: dhcp4: no addresses: - 10.0.1.10/24 routes: - to: 0.0.0.0/0 via: 10.0.1.253 nameservers: addresses: [1.1.1.1]  apply the /etc/netplan/01-netcfg.yaml configuration\nnetplan apply  display ip addresses on interfaces\nip address show  display all interfaces\nip link show  display routes\nroute -n  In order for Kubernetes to work, you need container runtime to be started\nsystemctl enable docker.service systemctl start docker.service  Download calicoctl, to be able to interact with calico with CLI\nsudo curl -O -L https://github.com/projectcalico/calicoctl/releases/download/v3.2.1/calicoctl sudo chmod +x calicoctl  To see the state of calico on nodes (BGP,Peer-type,up/down,time)\nsudo calicoctl node status  The following commands allow to export a variables with the IP address and ports of nginx-service previously created and access the content from the host or the container\nexport SERVICE_IP=$(kubectl get service nginx-service -o go-template='{{.spec.clusterIP}}') export SERVICE_PORT=$(kubectl get service nginx-service -o go-template='{{(index .spec.ports 0).port}}') wget -qO- http://$SERVICE_IP:$SERVICE_PORT kubectl run busybox --generator=run-pod/v1 --image=busybox --restart=Never --tty -i --env \u0026quot;SERVICE_IP=$SERVICE_IP\u0026quot; --env \u0026quot;SERVICE_PORT=$SERVICE_PORT\u0026quot; u@busybox$ wget -qO- http://$SERVICE_IP:$SERVICE_PORT # Run in the busybox container u@busybox$ exit # Exit the busybox container  noel@ubuntu-srv-1:~$ cat nginx-test.yaml apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2 kind: Deployment metadata: name: nginx-deployment-nbo spec: selector: matchLabels: app: nginx replicas: 3 # tells deployment to run 3 pods matching the template template: metadata: labels: app: nginx spec: volumes: - name: shared-data emptyDir: {} containers: - name: nginx image: nginx:1.7.9 volumeMounts: - name: shared-data mountPath: /usr/share/nginx/html ports: - containerPort: 80  https://kubernetes.io/docs/tutorials/k8s201/\napiVersion: v1 kind: Service metadata: name: nginx-service spec: ports: - port: 8000 # the port that this service should serve on # the container on each pod to connect to, can be a name # (e.g. 'www') or a number (e.g. 80) targetPort: 80 protocol: TCP # just like the selector in the deployment, # but this time it identifies the set of pods to load balance # traffic to. selector: app: nginx  These commands are to configure calicoctl in order to work with the local k8s\nexport CALICO_DATASTORE_TYPE=kubernetes export CALICO_KUBECONFIG=~/.kube/config Pour le root export CALICO_KUBECONFIG=/home/noel/.kube/config  Move the Calico mode from Always to CrossSubnet. First we get the calico ippool configuration, then we need to modify the ipipMode in the yaml file and eventually to apply the new configuration\ncalicoctl get ippool -o yaml \u0026gt; ippool.yaml  Change the mode ipipMode: CrossSubnet\ncalicoctl apply -f ippool.yaml  ","date":1538606240,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538606240,"objectID":"507e52dad9b1e639033f350fdc69e5dc","permalink":"https://netmemo.github.io/post/cheat-sheet-k8s-on-vms-with-calico/","publishdate":"2018-10-04T00:37:20+02:00","relpermalink":"/post/cheat-sheet-k8s-on-vms-with-calico/","section":"post","summary":"This is the cheat sheet for the post : https://netmemo.github.io/post/k8s-on-vms-with-calico/\nThe following post contain raw entry only for reminder purpose.\nBellow are the links I\u0026rsquo;ve used to understand/did my lab\nhttps://fr.wikipedia.org/wiki/Kubernetes#/media/File:Kubernetes.png https://kubernetes.io/docs/setup/independent/install-kubeadm/ https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/ https://kubernetes.io/docs/tutorials/k8s101/ https://kubernetes.io/docs/tutorials/k8s201/ https://kubernetes.io/docs/reference/kubectl/cheatsheet/\nJoin a node/worker to the master\nkubeadm join 10.0.1.10:6443 --token d34b9i.v03t2yiozio63cq6 --discovery-token-ca-cert-hash sha256:c21d04ea23790a0bf81cf64118e3a9075ffb63ed90bc697acef5793386e9eb16  Delete a deployment\nkubectl delete deployment nginx-deployment-nbo  To get the logs of a specific container. -n is to specify the namespace","tags":["calico","docker","k8s","kubernetes","netplan","ubuntu","virtualbox"],"title":"[Cheat Sheet] K8s on VMs with Calico","type":"post"}]