<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>netmemo.github.io on netmemo.github.io</title>
    <link>https://netmemo.github.io/</link>
    <description>Recent content in netmemo.github.io on netmemo.github.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>No&amp;euml;l Boul&amp;egrave;ne &amp;copy; 2021. This blog is strictly personnal and opinions expressed here are only mine and doesn&amp;#39;t reflect those of my past, current or futur employers. No warranty whatsoever is made that any of the posts are accurate. There is absolutely no assurance (apart from author&amp;acute;s professional integrity) that any statement contained in a post is true, correct or precise.</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Terraform One Step Further</title>
      <link>https://netmemo.github.io/post/terraform-one-step-further/</link>
      <pubDate>Wed, 26 Jan 2022 22:00:26 +0100</pubDate>
      
      <guid>https://netmemo.github.io/post/terraform-one-step-further/</guid>
      <description>

&lt;p&gt;This blog is in two parts. The &lt;a href=&#34;../terraform-bootstrap/&#34;&gt;first part&lt;/a&gt; explains what is needed to start with Terraform. This second part is to go one step further but still targets beginners.&lt;/p&gt;

&lt;p&gt;You can find more in depth articles on &lt;a href=&#34;https://blog.gruntwork.io/an-introduction-to-terraform-f17df9c6d180&#34;&gt;Gruntwork&lt;/a&gt; blog and the &lt;a href=&#34;https://www.terraform.io/language&#34;&gt;Terraform documentation&lt;/a&gt; is also very good.&lt;/p&gt;

&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of contents&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;../terraform-bootstrap/&#34;&gt;Terraform Bare minimum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#terraform-one-step-further&#34;&gt;Terraform one step further&lt;/a&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#what-happens-in-the-background&#34;&gt;What happens in the background ?&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#what-happens-if-we-modify-the-object-on-gui&#34;&gt;What happens if we modify the object on GUI ?&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-do-i-remove-configuration&#34;&gt;How do I remove configuration ?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#what-can-we-find-in-the-state-file&#34;&gt;What can we find in the state file ?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#terraform-components&#34;&gt;Terraform components&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#variables&#34;&gt;Variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#variables&#34;&gt;Files&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#commands&#34;&gt;Commands&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modules&#34;&gt;Modules&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scaling&#34;&gt;Scaling&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#workspaces&#34;&gt;Workspaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dry&#34;&gt;DRY&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;terraform-one-step-further&#34;&gt;Terraform one step further&lt;/h1&gt;

&lt;h3 id=&#34;what-happens-in-the-background&#34;&gt;What happens in the background ?&lt;/h3&gt;

&lt;p&gt;When the configuration is applied for the first time, it creates a state file to keep track of what is managed by Terraform.
The Terraform state file is a json file that you can read easily.&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
&lt;summary&gt;Click to display a state file&lt;/summary&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;version&amp;quot;: 4,
  &amp;quot;terraform_version&amp;quot;: &amp;quot;1.0.0&amp;quot;,
  &amp;quot;serial&amp;quot;: 5,
  &amp;quot;lineage&amp;quot;: &amp;quot;177474d1-df80-f405-45d1-c3a6b043b4b5&amp;quot;,
  &amp;quot;outputs&amp;quot;: {},
  &amp;quot;resources&amp;quot;: [
    {
      &amp;quot;mode&amp;quot;: &amp;quot;managed&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;aws_vpc&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;netmemo&amp;quot;,
      &amp;quot;provider&amp;quot;: &amp;quot;provider[\&amp;quot;registry.terraform.io/hashicorp/aws\&amp;quot;]&amp;quot;,
      &amp;quot;instances&amp;quot;: [
        {
          &amp;quot;schema_version&amp;quot;: 1,
          &amp;quot;attributes&amp;quot;: {
            &amp;quot;arn&amp;quot;: &amp;quot;arn:aws:ec2:us-east-2:919821450090:vpc/vpc-0c53f54e268772136&amp;quot;,
            &amp;quot;assign_generated_ipv6_cidr_block&amp;quot;: false,
            &amp;quot;cidr_block&amp;quot;: &amp;quot;10.0.0.0/16&amp;quot;,
            &amp;quot;default_network_acl_id&amp;quot;: &amp;quot;acl-0856dd4ead6188e7c&amp;quot;,
            &amp;quot;default_route_table_id&amp;quot;: &amp;quot;rtb-02f6f1824fca2ea83&amp;quot;,
            &amp;quot;default_security_group_id&amp;quot;: &amp;quot;sg-082ca88831aa7e0e5&amp;quot;,
            &amp;quot;dhcp_options_id&amp;quot;: &amp;quot;dopt-b98bcbd2&amp;quot;,
            &amp;quot;enable_classiclink&amp;quot;: null,
            &amp;quot;enable_classiclink_dns_support&amp;quot;: null,
            &amp;quot;enable_dns_hostnames&amp;quot;: false,
            &amp;quot;enable_dns_support&amp;quot;: true,
            &amp;quot;id&amp;quot;: &amp;quot;vpc-0c53f54e268772136&amp;quot;,
            &amp;quot;instance_tenancy&amp;quot;: &amp;quot;default&amp;quot;,
            &amp;quot;ipv6_association_id&amp;quot;: &amp;quot;&amp;quot;,
            &amp;quot;ipv6_cidr_block&amp;quot;: &amp;quot;&amp;quot;,
            &amp;quot;main_route_table_id&amp;quot;: &amp;quot;rtb-02f6f1824fca2ea83&amp;quot;,
            &amp;quot;owner_id&amp;quot;: &amp;quot;919821450090&amp;quot;,
            &amp;quot;tags&amp;quot;: null,
            &amp;quot;tags_all&amp;quot;: {}
          },
          &amp;quot;sensitive_attributes&amp;quot;: [],
          &amp;quot;private&amp;quot;: &amp;quot;eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ==&amp;quot;
        }
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/details&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;terraform-state.png&#34;&gt; &lt;img src=&#34;terraform-state.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;what-happens-if-we-modify-the-object-on-gui&#34;&gt;What happens if we modify the object on GUI ?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The configuration file is the intended configuration, it becomes the source of truth.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The resource is now managed by Terraform.&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If you apply the configuration again, it will compare it to the state file we have. If the resource is managed by Terraform it will implement the delta to make the production back as it was intended in the configuration file.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;details&gt;
&lt;summary&gt;Click to see what happens if you change the name of a VPC from the GUI and try to apply the configuration through Terraform again&lt;/summary&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;aws_vpc.netmemo: Refreshing state... [id=vpc-0fdab0a3c74e847ec]

Note: Objects have changed outside of Terraform

Terraform detected the following changes made outside of Terraform since the last &amp;quot;terraform apply&amp;quot;:

  # aws_vpc.netmemo has been changed
  ~ resource &amp;quot;aws_vpc&amp;quot; &amp;quot;netmemo&amp;quot; {
        id                               = &amp;quot;vpc-0fdab0a3c74e847ec&amp;quot;
      + tags                             = {
          + &amp;quot;Name&amp;quot; = &amp;quot;netmemo-vpc&amp;quot;
        }
      ~ tags_all                         = {
          + &amp;quot;Name&amp;quot; = &amp;quot;netmemo-vpc&amp;quot;
        }
        # (12 unchanged attributes hidden)
    }

Unless you have made equivalent changes to your configuration, or ignored the relevant attributes using ignore_changes, the following plan may include actions to undo or respond to these changes.

──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  ~ update in-place

Terraform will perform the following actions:

  # aws_vpc.netmemo will be updated in-place
  ~ resource &amp;quot;aws_vpc&amp;quot; &amp;quot;netmemo&amp;quot; {
        id                               = &amp;quot;vpc-0fdab0a3c74e847ec&amp;quot;
      ~ tags                             = {
          - &amp;quot;Name&amp;quot; = &amp;quot;netmemo-vpc&amp;quot; -&amp;gt; null
        }
      ~ tags_all                         = {
          - &amp;quot;Name&amp;quot; = &amp;quot;netmemo-vpc&amp;quot;
        } -&amp;gt; (known after apply)
        # (12 unchanged attributes hidden)
    }

Plan: 0 to add, 1 to change, 0 to destroy.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/details&gt;&lt;/p&gt;

&lt;h3 id=&#34;how-do-i-remove-configuration&#34;&gt;How do I remove configuration ?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;If you want to delete a specific resource, you just need to remove it from the Terraform configuration file. Terraform will take care of all the steps to delete it. It manages all the steps for you.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;It is the difference between a declarative approach and an imperative/procedural approach where you need to specify all the steps you need to do.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;details&gt;
&lt;summary&gt;Click to see what happens when you destroy a configuration&lt;/summary&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Terraform will perform the following actions:

  # aws_vpc.netmemo will be destroyed
  - resource &amp;quot;aws_vpc&amp;quot; &amp;quot;netmemo&amp;quot; {
      - arn                              = &amp;quot;arn:aws:ec2:us-east-2:919821450090:vpc/vpc-0fdab0a3c74e847ec&amp;quot; -&amp;gt; null
      - assign_generated_ipv6_cidr_block = false -&amp;gt; null
      - cidr_block                       = &amp;quot;10.0.0.0/16&amp;quot; -&amp;gt; null
      - default_network_acl_id           = &amp;quot;acl-0e677ba2378eaf56e&amp;quot; -&amp;gt; null
      - default_route_table_id           = &amp;quot;rtb-0ecb3bbec21918662&amp;quot; -&amp;gt; null
      - default_security_group_id        = &amp;quot;sg-0c41be3848fca4e83&amp;quot; -&amp;gt; null
      - dhcp_options_id                  = &amp;quot;dopt-b98bcbd2&amp;quot; -&amp;gt; null
      - enable_dns_hostnames             = false -&amp;gt; null
      - enable_dns_support               = true -&amp;gt; null
      - id                               = &amp;quot;vpc-0fdab0a3c74e847ec&amp;quot; -&amp;gt; null
      - instance_tenancy                 = &amp;quot;default&amp;quot; -&amp;gt; null
      - main_route_table_id              = &amp;quot;rtb-0ecb3bbec21918662&amp;quot; -&amp;gt; null
      - owner_id                         = &amp;quot;919821450090&amp;quot; -&amp;gt; null
      - tags                             = {
          - &amp;quot;Name&amp;quot; = &amp;quot;netmemo-vpc&amp;quot;
        } -&amp;gt; null
      - tags_all                         = {
          - &amp;quot;Name&amp;quot; = &amp;quot;netmemo-vpc&amp;quot;
        } -&amp;gt; null
    }

Plan: 0 to add, 0 to change, 1 to destroy.

Changes to Outputs:
  - test-output = &amp;quot;iam testing&amp;quot; -&amp;gt; null

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only &#39;yes&#39; will be accepted to confirm.

  Enter a value: yes

aws_vpc.netmemo: Destroying... [id=vpc-0fdab0a3c74e847ec]
aws_vpc.netmemo: Destruction complete after 1s

Destroy complete! Resources: 1 destroyed.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/details&gt;&lt;/p&gt;

&lt;h3 id=&#34;what-can-we-find-in-the-state-file&#34;&gt;What can we find in the state file ?&lt;/h3&gt;

&lt;p&gt;There are 3 types of objects in the state file:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Object&lt;/th&gt;
&lt;th&gt;Mode&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Resource&lt;/td&gt;
&lt;td&gt;Managed&lt;/td&gt;
&lt;td&gt;What we create and manage through our Terraform script&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Datasource&lt;/td&gt;
&lt;td&gt;Data&lt;/td&gt;
&lt;td&gt;import production object and work with their attributes. For instance, import a VPC that is not managed by Terraform and use the vpc_id to assign a subnet&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Output&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;Variables&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;details&gt;
&lt;summary&gt;Click to see a resource&lt;/summary&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;mode&amp;quot;: &amp;quot;managed&amp;quot;,
    &amp;quot;type&amp;quot;: &amp;quot;aws_vpc&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;netmemo&amp;quot;,
    &amp;quot;provider&amp;quot;: &amp;quot;provider[\&amp;quot;registry.terraform.io/hashicorp/aws\&amp;quot;]&amp;quot;,
    &amp;quot;instances&amp;quot;: [
      {
        &amp;quot;schema_version&amp;quot;: 1,
        &amp;quot;attributes&amp;quot;: {
          &amp;lt;snip&amp;gt; ..... &amp;lt;snip&amp;gt;
        },
        &amp;quot;sensitive_attributes&amp;quot;: [],
        &amp;quot;private&amp;quot;: &amp;quot;*****fdmVyc2lvbiI6IjEifQ==&amp;quot;
      }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/details&gt;&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
&lt;summary&gt;Click to see a datasource&lt;/summary&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    {
      &amp;quot;mode&amp;quot;: &amp;quot;data&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;aws_iam_policy&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;vpcpolicy&amp;quot;,
      &amp;quot;provider&amp;quot;: &amp;quot;provider[\&amp;quot;registry.terraform.io/hashicorp/aws\&amp;quot;]&amp;quot;,
      &amp;quot;instances&amp;quot;: [
        {
          &amp;quot;schema_version&amp;quot;: 0,
          &amp;quot;attributes&amp;quot;: {
            &amp;lt;snip&amp;gt; ..... &amp;lt;snip&amp;gt;
          },
          &amp;quot;sensitive_attributes&amp;quot;: []
        }
      ]
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/details&gt;&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
&lt;summary&gt;Click to see an output&lt;/summary&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;quot;outputs&amp;quot;: {
    &amp;quot;test-output&amp;quot;: {
      &amp;quot;value&amp;quot;: &amp;quot;iam testint&amp;quot;,
      &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/details&gt;&lt;/p&gt;

&lt;h1 id=&#34;terraform-components&#34;&gt;Terraform components&lt;/h1&gt;

&lt;h3 id=&#34;variables&#34;&gt;Variables&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Outputs:
This will store variables in the output section of the state file. It will also be displayed at the screen terminal when the command “plan” and “apply” are executed. Only output variables can be accessed from other Terraform modules.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Locals:
Allow to define named values that you can refer to in your configuration. It helps to do variable manipulation or substitution to make the code more readable. Use local values only in moderation, in situation where a single value or result is used in many places and that value is likely to be changed in future. The ability to easily change the value in a central place is the key advantage of local values.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;locals {
# Ids for multiple sets of EC2 instances, merged together
instance_ids = concat(aws_instance.blue.*.id, aws_instance.green.*.id)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Inputs:
It serves as parameters for a Terraform module.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Comparing to traditional programming language
Output values are like function return values.
Local values are like a function’s temporary local variables.
Input variables are like function arguments&lt;/p&gt;

&lt;h3 id=&#34;files&#34;&gt;Files&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;├─ main.tf
├─ provider.tf
├─ variables.tf
├─ outputs.tf
├─ terraform.tfvars
├─ terraform.tfstate
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;.tf&lt;/strong&gt;&lt;br /&gt;
The main file can be split into different files for the readers&amp;rsquo; convenience. The name of the .tf file can be anything. Most of the time we find:&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;File&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;main.tf&lt;/td&gt;
&lt;td&gt;Resources definition&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;provider.tf&lt;/td&gt;
&lt;td&gt;Provider definition&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;variable.tf&lt;/td&gt;
&lt;td&gt;Variable &lt;strong&gt;declaration&lt;/strong&gt; (name + type)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;outputs.tf&lt;/td&gt;
&lt;td&gt;outputs variables&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;terraform.tfvars&lt;/strong&gt;&lt;br /&gt;
It contains the input variables &lt;strong&gt;definitions&lt;/strong&gt; (value). This is used with “module” where we need different variables per infrastructure. Otherwise, the variable definition can be embedded in the default section of the variable declaration in the Terraform configuration file.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;terraform.tfstate&lt;/strong&gt;&lt;br /&gt;
To store the current state of the Terraform managed infrastructure.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;variable-declaration-and-definition&#34;&gt;Variable declaration and definition&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt; #declaration + type
 variable &amp;quot;cidr&amp;quot; {
     type = string
 }
 
 #value
 cidr = &amp;quot;10.0.0.0/24&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;commands&#34;&gt;Commands&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;terraform init&lt;/code&gt; : Download the providers.&lt;br /&gt;
&lt;code&gt;terraform plan&lt;/code&gt; : Allow to dissociate the “plan” from the “apply”. It compares the previous state and the intended config and tells you what it will plan to do to make the production as intended. With this command you can save the plan to directly apply it with the apply command when you are ready.&lt;br /&gt;
&lt;code&gt;terraform show&lt;/code&gt; : Display the current state file or the plan file created with the plan command.&lt;br /&gt;
&lt;code&gt;terraform apply&lt;/code&gt; : Push the configuration to production.&lt;br /&gt;
&lt;code&gt;terraform destroy&lt;/code&gt; : Delete all the configuration. It can be useful in CI/CD environment when we want to test things and destroy afterwards.&lt;/p&gt;

&lt;h3 id=&#34;modules&#34;&gt;Modules&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;terraform-module.png&#34;&gt; &lt;img src=&#34;terraform-module.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Root module.&lt;br /&gt;
This is the main program that will create the infrastructure.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Child module.&lt;br /&gt;
This is the module called from the root module. It allows to externalize repeatable code. By centralizing the code, it becomes more manageable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;scaling&#34;&gt;Scaling&lt;/h1&gt;

&lt;h3 id=&#34;workspaces&#34;&gt;Workspaces&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Workspaces&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;Shared storage for state files : Access to all members of the team&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Locking state files : Prevent concurrent modification&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Isolating state files : Several environments and variables&lt;br /&gt;
&lt;BR&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Terraform Cloud/Enterprise&lt;br /&gt;
This is an infrastructure component SaaS for Terraform Cloud and on-premises server for Terraform Enterprise.
This software allows to manage workspaces, variables, state file locking, password and provide API to interface Terraform with other software like Github.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;terraform-tfe.png&#34;&gt; &lt;img src=&#34;terraform-tfe.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;dry&#34;&gt;DRY&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Keep your code DRY (Don’t Repeat Yourself)&lt;br /&gt;
&lt;a href=&#34;https://www.terraform.io/language/meta-arguments/for_each&#34;&gt;for_each&lt;/a&gt; : Allow to loop over a resource to create it several times according to variables that you define in your variable.tf file.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Without for_each&lt;/strong&gt;&lt;br /&gt;
Every time you add a subnet you need to create an entire block of resources.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource “aws_subnet” “subnet1” {
   cidr_block	= “10.0.1.0/24”
   vpc_id	= “myvpcid”
}

resource “aws_subnet” “subnet2” {
   cidr_block	= “10.0.2.0/24”
   vpc_id	= “myvpcid”
}

resource “aws_subnet” “subnet13” {
   cidr_block	= “10.0.3.0/24”
   vpc_id	= “myvpcid”
}

resource “aws_subnet” “subnet4” {
   cidr_block	= “10.0.4.0/24”
   vpc_id	= “myvpcid”
}

resource “aws_subnet” “subnet5” {
   cidr_block	= “10.0.5.0/24”
   vpc_id	= “myvpcid”
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;With for_each&lt;/strong&gt;&lt;br /&gt;
Every time you add a subnet you need add a line in the variable.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#variable declaration
variable “setofsubnet” {
    type = set(string)
}

#variable definition
setofsubnet = [
   “10.0.1.0/24”,
   “10.0.2.0/24”,
   “10.0.3.0/24”,
   “10.0.4.0/24”,
   “10.0.5.0/24”
]

#resource creation
resource “aws_subnet” “main-subnet” {
   for_each = var.listofsubnet
   cidr_block = each.key
   vpc_id = “myvpcid”
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can find very good &lt;a href=&#34;https://blog.gruntwork.io/terraform-tips-tricks-loops-if-statements-and-gotchas-f739bbae55f9&#34;&gt;tips&lt;/a&gt; around loops on the Gruntwork blog.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terraform Bootstrap</title>
      <link>https://netmemo.github.io/post/terraform-bootstrap/</link>
      <pubDate>Wed, 19 Jan 2022 18:40:34 +0100</pubDate>
      
      <guid>https://netmemo.github.io/post/terraform-bootstrap/</guid>
      <description>

&lt;p&gt;This blog is in two parts. This first part explains what is needed to start with Terraform, the &lt;a href=&#34;../terraform-one-step-further/&#34;&gt;second part&lt;/a&gt; is to go one step further but still targets beginners.&lt;/p&gt;

&lt;h1 id=&#34;table-of-content&#34;&gt;Table of content&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#terraform-bare-minimum&#34;&gt;Terraform bare minimum&lt;/a&gt;&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#terraform-what-is-it&#34;&gt;Terraform, what is it ?&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#what-do-you-need-to-provision-something-with-terraform&#34;&gt;What do I need to provision something with Terraform ?&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-do-i-know-what-to-create&#34;&gt;How do I know what to create ?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-configuration-is-made-of-3-blocks&#34;&gt;The configuration is made of 3 blocks&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#you-need-2-commands-to-push-your-first-configuration&#34;&gt;You need 2 commands to push your first configuration&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#demo-time&#34;&gt;Demo time&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;../terraform-one-step-further/&#34;&gt;One step further&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;terraform-bare-minimum&#34;&gt;Terraform bare minimum&lt;/h1&gt;

&lt;h3 id=&#34;terraform-what-is-it&#34;&gt;Terraform, what is it ?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/&#34;&gt;Terraform&lt;/a&gt; allows to manage infrastructure thanks to the configuration file known as infrastructure as Code (IaC). It allows to create reproducible infrastructure.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/&#34;&gt;Terraform&lt;/a&gt; determines what has changed and creates incremental execution plans that respect dependencies. It is &lt;a href=&#34;https://en.wikipedia.org/wiki/Idempotence&#34;&gt;idempotent&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;what-do-i-need-to-provision-something-with-terraform&#34;&gt;What do I need to provision something with Terraform ?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/downloads&#34;&gt;terraform.exe&lt;/a&gt; file&lt;/li&gt;
&lt;li&gt;One configuration file&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;terraform-simple.png&#34;&gt; &lt;img src=&#34;terraform-simple.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;how-do-i-know-what-to-create&#34;&gt;How do I know what to create ?&lt;/h3&gt;

&lt;p&gt;Most of the time you need the &lt;a href=&#34;https://registry.terraform.io/namespaces/hashicorp&#34;&gt;documentation&lt;/a&gt; of the provider you want to use. The &lt;a href=&#34;https://registry.terraform.io/namespaces/hashicorp&#34;&gt;documentation&lt;/a&gt; often respect the same structure and it&amp;rsquo;s easy to browse.
These are the main providers that I use &lt;a href=&#34;https://registry.terraform.io/providers/vmware/nsxt/latest/docs&#34;&gt;NSX-T&lt;/a&gt;/&lt;a href=&#34;https://registry.terraform.io/providers/CiscoDevNet/aci/latest/docs&#34;&gt;ACI&lt;/a&gt;/&lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/aws/latest/docs&#34;&gt;AWS&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-configuration-is-made-of-3-blocks&#34;&gt;The configuration is made of 3 blocks&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Block&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Terraform&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;What&lt;/strong&gt; provider to use&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Provider&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Where&lt;/strong&gt; to push the configuration&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Resources&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;What&lt;/strong&gt; to create&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code&gt;terraform provider{
    required_provider{
        aws = {
            source  = &amp;quot;hashicorp/aws&amp;quot;
            version = &amp;quot;3.55.0&amp;quot;
        }
    }
}

provider &amp;quot;aws&amp;quot; {
    region = &amp;quot;us-east-2&amp;quot;
    access_-_key = &amp;quot;**********&amp;quot;
    secret_key = &amp;quot;**********&amp;quot;
}

resource &amp;quot;aws_s3_bucket&amp;quot; &amp;quot;netmemo_bucket&amp;quot; {
    bucket = &amp;quot;netmemo_bucket&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;you-need-2-commands-to-push-your-first-configuration&#34;&gt;You need 2 commands to push your first configuration&lt;/h3&gt;

&lt;p&gt;When the first initialization has been done, you will only need the apply command for the next infrastructure modifications.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;terraform init&lt;/code&gt;      =&amp;gt; Download and configure the provider&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;terraform apply&lt;/code&gt;     =&amp;gt; It tells you what it will do then push the configuration&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;proxy-white-listing&#34;&gt;Proxy white listing&lt;/h3&gt;

&lt;p&gt;In enterprise, don’t forget to whitelist URLs. Below is an example for AWS.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To download the providers / backend init&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://registry.terraform.io&#34;&gt;https://registry.terraform.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://releases.hashicorp.com&#34;&gt;https://releases.hashicorp.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;To authenticate to the providers

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://iam.amazonaws.com/&#34;&gt;https://iam.amazonaws.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sts.amazonaws.com/&#34;&gt;https://sts.amazonaws.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;To push the configuration

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://us-east-2.amazonaws.com/&#34;&gt;https://us-east-2.amazonaws.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;demo-time&#34;&gt;DEMO TIME&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;terraform-demo.gif&#34;&gt; &lt;img src=&#34;terraform-demo.gif&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cisco ACI Terraform Policy Model</title>
      <link>https://netmemo.github.io/post/aci-terraform-policy-model/</link>
      <pubDate>Wed, 15 Dec 2021 18:40:34 +0100</pubDate>
      
      <guid>https://netmemo.github.io/post/aci-terraform-policy-model/</guid>
      <description>

&lt;h1 id=&#34;the-big-picture&#34;&gt;The big picture&lt;/h1&gt;

&lt;p&gt;This blog post is a memo for the ACI Terraform policy model. I have struggled to find equivalences between ACI REST API Call / Classes and Terraform resources. Below you can find the full diagram. The diagram is not exhaustive but I think I have reached a point where I can published something. I will probably modify or add things if I use more resources or if people correct me but I think it is a good start. L3 out is very complex that&amp;rsquo;s why the diagram ends up being complex. I don&amp;rsquo;t cover all cases for L3 out, only the one I have been using so far.&lt;/p&gt;

&lt;p&gt;You will be able to find the source of this diagram &lt;a href=&#34;https://github.com/netmemo/netmemo.github.io/tree/master/post/aci-terraform-policy-model/aci-l3out-blog.drawio&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;ACI-L3out-3-full.drawio.png&#34;&gt; &lt;img src=&#34;ACI-L3out-3-full.drawio.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;the-small-picture&#34;&gt;The small picture&lt;/h1&gt;

&lt;p&gt;This second diagram is lighter. This is when you are not using L3out or static path bing and contracts. It looks more like the &amp;ldquo;Figure 1.&amp;rdquo; in Fabric Connectivity chapter of &lt;a href=&#34;https://www.cisco.com/c/en/us/td/docs/switches/datacenter/aci/apic/sw/1-x/Operating_ACI/guide/b_Cisco_Operating_ACI/b_Cisco_Operating_ACI_chapter_0110.html&#34;&gt;Operating Cisco Application Centric Infrastructure&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;ACI-L3out-3-light.drawio.png&#34;&gt; &lt;img src=&#34;ACI-L3out-3-light.drawio.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Can we ping an AWS Lambda function ?</title>
      <link>https://netmemo.github.io/post/lambdaping/</link>
      <pubDate>Tue, 16 Nov 2021 18:00:45 +0200</pubDate>
      
      <guid>https://netmemo.github.io/post/lambdaping/</guid>
      <description>

&lt;h1 id=&#34;context&#34;&gt;Context&lt;/h1&gt;

&lt;p&gt;Can we ping the ENI of an AWS Lambda function within the VPC ? While the answer can be &lt;a href=&#34;#obvious&#34;&gt;obvious&lt;/a&gt; the path to get it was insightful for me and has helped me to be more comfortable with :&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;AWS IAM.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;AWS Lambdas function.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;AWS Static IP addresses and AWS default subnets.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This test can be performed with the AWS free tier. You will find the Terraform scripts here : &lt;a href=&#34;https://github.com/netmemo/lambdaping&#34;&gt;Lambda Ping&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I am a network engineer, I like diagram. Below you can find the diagram of the test.
&lt;a href=&#34;lambdaping.png&#34;&gt; &lt;img src=&#34;lambdaping.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What needs to be created&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Infrastrusture:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;aws_key_pair&lt;/li&gt;
&lt;li&gt;aws_default_subnet&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;aws_security_group&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;aws_instance&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Script:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A python script executed with the AWS lambda function&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;IAM:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;aws_iam_role&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;aws_iam_role_policy_attachment&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;aws_iam_policy&lt;/li&gt;
&lt;li&gt;aws_iam_policy_document&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Lambda:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;aws_lambda_function&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This test is a good demonstration of one of the terraform benefits. Terraform is taking care of the dependencies and the order of creation between all resources.
In the case of an imperative model for &lt;strong&gt;aws_key_pair&lt;/strong&gt; and &lt;strong&gt;aws_instance&lt;/strong&gt; you will need to explicitly state that &lt;strong&gt;aws_key_pair&lt;/strong&gt; needs to be created before &lt;strong&gt;aws_instance&lt;/strong&gt; is created. With the declarative approach of Terraform, you just declare the resources you want and Terraform is taking care of the execution order.&lt;/p&gt;

&lt;h1 id=&#34;resources-creation&#34;&gt;Resources creation&lt;/h1&gt;

&lt;h2 id=&#34;infrastructure&#34;&gt;Infrastructure&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;aws_key&lt;/strong&gt;&lt;br /&gt;
This is to push the public key of the computer that will be allowed to connect to the EC2 VM Instance.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_key_pair&amp;quot; &amp;quot;deployer&amp;quot; {
	key_name   = &amp;quot;deployer-key&amp;quot;
	public_key = file(&amp;quot;~/.ssh/id_rsa.pub&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;aws_default_subnet&lt;/strong&gt;&lt;br /&gt;
This resource &lt;strong&gt;can&amp;rsquo;t&lt;/strong&gt; modify the default subnet address but it allows you to retrieve it from your default VPC.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_default_subnet&amp;quot; &amp;quot;default_az1&amp;quot; {
  availability_zone = &amp;quot;us-east-2a&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;aws_security_group&lt;/strong&gt;&lt;br /&gt;
This will be the security group for the test. This security group will be assigned to the VM and the AWS lambda function to allow SSH to the VM, HTTP, ICMP between each other and outgoing traffic.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_security_group&amp;quot; &amp;quot;sglambdaping&amp;quot; {
  name        = &amp;quot;sglambdaping&amp;quot;
  description = &amp;quot;Allow HTTP, ICMP and SSH traffic&amp;quot;

  ingress {
    description = &amp;quot;SSH&amp;quot;
    from_port   = 22
    to_port     = 22
    protocol    = &amp;quot;tcp&amp;quot;
    cidr_blocks = [&amp;quot;0.0.0.0/0&amp;quot;]
  }

  ingress {
    description = &amp;quot;HTTP&amp;quot;
    from_port   = 80
    to_port     = 80
    protocol    = &amp;quot;tcp&amp;quot;
    cidr_blocks = [&amp;quot;0.0.0.0/0&amp;quot;]
  }

  ingress {
    description = &amp;quot;ALL_ICMP&amp;quot;
    from_port = -1
    to_port = -1
    protocol = &amp;quot;icmp&amp;quot;
    cidr_blocks = [&amp;quot;0.0.0.0/0&amp;quot;]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = &amp;quot;-1&amp;quot;
    cidr_blocks = [&amp;quot;0.0.0.0/0&amp;quot;]
  }

  tags = {
    Name = &amp;quot;terraform&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;aws_instance&lt;/strong&gt;&lt;br /&gt;
The t2.micro VM instance. It will host one webserver to test that the &lt;a href=&#34;https://aws.amazon.com/blogs/compute/announcing-improved-vpc-networking-for-aws-lambda-functions/&#34;&gt;ENI&lt;/a&gt; of the Lambda function works in our VPC by accessing it. This is also from this VM that we will try to ping the Lambda function&amp;rsquo;s ENI. I assign the VM to the default subnet of AZ1 which is normally 172.31.0.0/24. In the Terraform script I&amp;rsquo;m installing the webserver. I also assign a static IP address to be able to access the web server from the lambda function.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_instance&amp;quot; &amp;quot;foo&amp;quot; {
  ami           = &amp;quot;ami-0443305dabd4be2bc&amp;quot;
  instance_type = &amp;quot;t2.micro&amp;quot;
  key_name      = aws_key_pair.deployer.key_name

  user_data     = &amp;lt;&amp;lt;-EOF
                  #!/bin/bash
                  sudo su
                  yum -y install httpd
                  echo &amp;quot;&amp;lt;p&amp;gt; My Instance! &amp;lt;/p&amp;gt;&amp;quot; &amp;gt;&amp;gt; /var/www/html/index.html
                  sudo systemctl enable httpd
                  sudo systemctl start httpd
                  EOF

  vpc_security_group_ids = [
    aws_security_group.ubuntu.id
  ]

  private_ip = &amp;quot;172.31.0.8&amp;quot;
  subnet_id  = aws_default_subnet.default_az1.id
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;python-script&#34;&gt;Python script&lt;/h2&gt;

&lt;p&gt;For the lambda part we first need a code that the function will execute. In this example it will be a HTTP request to our EC2 VM done with python urllib3 library.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#import json
import urllib3

print(&#39;Loading function&#39;)
def lambda_handler(event, context):
    http = urllib3.PoolManager()
    resp = http.request(&amp;quot;GET&amp;quot;, &amp;quot;http://172.31.0.8&amp;quot;)
    print(resp.data)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once the script is ready, you need to zip it then place the zip in the same directory as your Terraform script that will create the function.
We then need to create the lambda resources.&lt;/p&gt;

&lt;h2 id=&#34;iam&#34;&gt;IAM&lt;/h2&gt;

&lt;p&gt;In this &lt;a href=&#34;https://netmemo.github.io/post/tf-iam-roles/&#34;&gt;post&lt;/a&gt; I explain in detail what the role, the assume_role_policy and the policy are used for.&lt;/p&gt;

&lt;p&gt;First we load a default AWS Managed Policy that will allow the lambda function to create the ENI in the VPC.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;aws_iam_policy&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data &amp;quot;aws_iam_policy&amp;quot; &amp;quot;vpcpolicy&amp;quot; {
 name = &amp;quot;AWSLambdaVPCAccessExecutionRole&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We then create the role that will use this policy.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;aws_iam_role&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_iam_role&amp;quot; &amp;quot;role-lambda&amp;quot; {
  name               = &amp;quot;nbolambdarole&amp;quot;
  assume_role_policy = data.aws_iam_policy_document.lambda_role.json
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this role we need to mention who will use it. In our case this is the lambda function. This action is done by defining a policy document where the principal is a lambda function.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;aws_iam_policy_document&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data &amp;quot;aws_iam_policy_document&amp;quot; &amp;quot;lambda_role&amp;quot; {
  statement {
    effect  = &amp;quot;Allow&amp;quot;
    actions = [&amp;quot;sts:AssumeRole&amp;quot;]

    principals {
      type        = &amp;quot;Service&amp;quot;
      identifiers = [&amp;quot;lambda.amazonaws.com&amp;quot;]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we assign this policy to the assume_role_policy of the role&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  assume_role_policy = data.aws_iam_policy_document.lambda_role.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last step of the IAM configuration is to attach the role and the policy together.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;aws_iam_role_policy_attachment&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_iam_role_policy_attachment&amp;quot; &amp;quot;role-policy-attach&amp;quot; {
  role       = aws_iam_role.role-lambda.name
  policy_arn = data.aws_iam_policy.vpcpolicy.arn
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;lambda&#34;&gt;Lambda&lt;/h2&gt;

&lt;p&gt;Once the IAM part is done, we can create the lambda function. In our case we assign the previously created role to the function and the python script zip file.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;aws_lambda_function&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_lambda_function&amp;quot; &amp;quot;lambda-get&amp;quot; {
  function_name = &amp;quot;nbo-tf-helloword-3&amp;quot;
  role          = aws_iam_role.role-lambda.arn
  filename         = &amp;quot;lambda_function.zip&amp;quot;
  source_code_hash = filebase64sha256(&amp;quot;lambda_function.zip&amp;quot;)
  runtime = &amp;quot;python3.9&amp;quot;
  handler = &amp;quot;lambda_function.lambda_handler&amp;quot;

  vpc_config {
      subnet_ids = [aws_default_subnet.default_az1.id]
      security_group_ids = [aws_security_group.sglambda.id]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;strong&gt;source_code_hash&lt;/strong&gt; is used to see if the lambda function has changed and then need to be updated.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;The &lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/python-handler.html&#34;&gt;handler&lt;/a&gt; is normally the name of the python script dot the name of the python method you want to execute.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;vpc_config&lt;/strong&gt; is the VPC part of the lambda configuration to specify the security group associated to the lambda ENI and the subnet where the ENI will be.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;the-tests&#34;&gt;The tests&lt;/h2&gt;

&lt;p&gt;Lambda will access the web server to validate the communication. To launch the test, we need to create an empty event that will be selected when we will click on the orange test button.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;test-event.png&#34;&gt; &lt;img src=&#34;test-event.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Click on the orange test button :) It should reply &amp;ldquo;My Instance&amp;rdquo;
&lt;a href=&#34;lambda-request.png&#34;&gt; &lt;img src=&#34;lambda-request.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&#34;obvious&#34;&gt;&lt;/a&gt;&lt;br /&gt;
After the communication is validated, we can connect to the EC2 VM instance to launch the ping command. It will fail to ping the Lambda function.&lt;br /&gt;
&lt;a href=&#34;ping-fail.png&#34;&gt; &lt;img src=&#34;ping-fail.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;challenges-of-this-test&#34;&gt;Challenges of this test&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Understand the AWS IAM concept for the lambda function. The lambda function needs VPC rights to create the ENI in the VPC.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Find what default python library was available with AWS python to execute the HTTP request.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Understand how the lambda tests are done and what is a &lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/python-handler.html&#34;&gt;handler&lt;/a&gt;.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>AWS IAM Roles with Terraform</title>
      <link>https://netmemo.github.io/post/tf-iam-roles/</link>
      <pubDate>Mon, 27 Sep 2021 18:04:31 +0200</pubDate>
      
      <guid>https://netmemo.github.io/post/tf-iam-roles/</guid>
      <description>

&lt;p&gt;An IAM role is an AWS identity with permission policies that determine what the identity can and cannot do in AWS.&lt;/p&gt;

&lt;h1 id=&#34;tl-dr&#34;&gt;TL;DR&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;strong&gt;&lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_principal.html&#34;&gt;principal&lt;/a&gt;&lt;/strong&gt; is &lt;strong&gt;WHO&lt;/strong&gt; will be able to access a resource.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;policy&lt;/strong&gt; is &lt;strong&gt;WHAT&lt;/strong&gt; the principals associated with the role will be able to do.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;role&lt;/strong&gt; links the principals thanks to the &lt;em&gt;assume_role_policy&lt;/em&gt; with the &lt;em&gt;inline policy&lt;/em&gt; argument.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;attachement&lt;/strong&gt; links the role to a &lt;em&gt;managed policies&lt;/em&gt; instead of the &lt;em&gt;inline policy&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;aws-iam-simple.png&#34;&gt; &lt;img src=&#34;aws-iam-simple.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;terraform-resources-and-aws-api&#34;&gt;Terraform resources and AWS API&lt;/h1&gt;

&lt;h3 id=&#34;policy&#34;&gt;Policy&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy&#34;&gt;aws_iam_policy&lt;/a&gt; | &lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/APIReference/API_CreatePolicy.html&#34;&gt;aws create policy API&lt;/a&gt;&lt;br /&gt;
There are 3 types of policies.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Inline :  The policy is defined directly in the object that needs it.&lt;/li&gt;
&lt;li&gt;Managed : More flexible, can be reused with several roles. Need to be attached with an object.&lt;/li&gt;
&lt;li&gt;AWS Managed : Same advantages as the managed ones but can&amp;rsquo;t be modified.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here is a link that helps to &lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html#choosing-managed-or-inline&#34;&gt;choose&lt;/a&gt; between them.&lt;/p&gt;

&lt;h3 id=&#34;role&#34;&gt;Role&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role&#34;&gt;aws_iam_role&lt;/a&gt; | &lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/APIReference/API_CreateRole.html&#34;&gt;aws create role API&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is to define the IAM role resource that will link the principals and the policy.&lt;br /&gt;
If we are using &lt;em&gt;managed policy&lt;/em&gt; we will need to link this role to the &lt;em&gt;managed policy&lt;/em&gt; with an attachment resource. In case of using &lt;em&gt;inline policy&lt;/em&gt;, the &lt;em&gt;inline policy&lt;/em&gt; is declared in the Terraform resource role. With AWS API, it needs &lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/APIReference/API_PutRolePolicy.html&#34;&gt;another API call&lt;/a&gt; to set the &lt;em&gt;inline policy&lt;/em&gt; in the &lt;em&gt;role&lt;/em&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;assume_role_policy&lt;/strong&gt;&lt;br /&gt;
This is a mandatory argument used in aws_iam_role and aws_iam_role_policy to indicate &lt;strong&gt;WHO&lt;/strong&gt; can temporarily assume the role that we are defining. It&amp;rsquo;s also referred as trust policy.&lt;br /&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/44628380/terraform-assume-role-policy-similar-but-slightly-different-than-standard-ia&#34;&gt;explanation 1&lt;/a&gt;, &lt;a href=&#34;https://aws.amazon.com/blogs/security/how-to-use-trust-policies-with-iam-roles/&#34;&gt;explanation 2&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;attachments&#34;&gt;Attachments&lt;/h3&gt;

&lt;p&gt;Attach a &lt;em&gt;managed policy&lt;/em&gt; to a group, user or role&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_group_policy_attachment&#34;&gt;aws_iam_group_policy_attachment&lt;/a&gt; | &lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/APIReference/API_AttachGroupPolicy.html&#34;&gt;aws attach group policy API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_user_policy_attachment&#34;&gt;aws_iam_user_policy_attachment&lt;/a&gt; | &lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/APIReference/API_AttachUserPolicy.html&#34;&gt;aws attach user policy API&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role_policy_attachment&#34;&gt;aws_iam_role_policy_attachment&lt;/a&gt; | &lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/APIReference/API_AttachRolePolicy.html&#34;&gt;aws attach role policy API&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;possibilities-of-policy-attachment&#34;&gt;Possibilities of policy attachment&lt;/h1&gt;

&lt;p&gt;From the less flexible to the most flexible:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1 resource: aws_iam_role with &lt;em&gt;inline_policy&lt;/em&gt; argument&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;2 resources: aws_iam_role + aws_iam_role_policy (conflict with aws_iam_role / inline_policy)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;3 resources: aws_iam_role + aws_iam_policy + aws_iam_role_policy_attachment&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;terraform-specific-resources&#34;&gt;Terraform specific resources&lt;/h1&gt;

&lt;h3 id=&#34;datasource&#34;&gt;Datasource&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/iam_policy_document&#34;&gt;aws_iam_policy_document&lt;/a&gt;.
This is an optional datasource which is Terraform specific. The policy defined in HCL format is translated to JSON when associated with the inline policy attribute of the role.
The advantages of using this &lt;a href=&#34;https://learn.hashicorp.com/tutorials/terraform/aws-iam-policy?_ga=2.99142555.466421101.1630266824-70591653.1623679226&#34;&gt;Policy in HCL format&lt;/a&gt; are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Being able to overwrite, append, or update policies with this resource by using the source_json and override_json arguments.&lt;/li&gt;
&lt;li&gt;Terraform error checking automatically formats your policy document into correct JSON when you run your apply.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Data sources make it easier to reuse policies throughout your environment.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It can be used in the below resources.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;aws_iam_policy / &lt;em&gt;policy&lt;/em&gt; argument&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;aws_iam_role_policy / &lt;em&gt;policy&lt;/em&gt; argument&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;aws_iam_role_policy / &lt;em&gt;assume_role_policy&lt;/em&gt; argument&lt;/li&gt;
&lt;li&gt;aws_iam_role / &lt;em&gt;assume_role_policy&lt;/em&gt; argument&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;inline-policy-resources&#34;&gt;Inline policy resources&lt;/h3&gt;

&lt;p&gt;Provide an IAM user/role/group with an inline policy.
The aim is to reduce the number of Terraform resources to give access to a role/user/group. You can directly use them instead of creating a role/user/group, the policy and the attachement to link both (2 vs 3 resources).
There is an &lt;strong&gt;overlap&lt;/strong&gt; between the &lt;em&gt;aws_iam_role_policy&lt;/em&gt; and the &lt;em&gt;aws_iam_role&lt;/em&gt; / &lt;em&gt;inline_policy&lt;/em&gt; argument. There are incompatible.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_user_policy&#34;&gt;aws_iam_user_policy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role_policy&#34;&gt;aws_iam_role_policy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_group_policy&#34;&gt;aws_iam_group_policy&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;attachment&#34;&gt;Attachment&lt;/h3&gt;

&lt;p&gt;There are lots of &lt;strong&gt;overlap&lt;/strong&gt;, &lt;strong&gt;incompatibility&lt;/strong&gt; and &lt;strong&gt;conflict&lt;/strong&gt; with this resource.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_policy_attachment&#34;&gt;aws_iam_policy_attachment&lt;/a&gt; EXCLUSIVE with other attachements.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;conflict with aws_iam_user_policy_attachment, aws_iam_group_policy_attachment, aws_iam_role_policy_attachment&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;bonus&#34;&gt;Bonus :)&lt;/h3&gt;

&lt;p&gt;As a bonus here are the &lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_iam-quotas.html&#34;&gt;quotas&lt;/a&gt; for IAM and STS&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Github Actions with Terraform Cloud for CI/CD of NSX-T</title>
      <link>https://netmemo.github.io/post/tf-gha-nsxt-cicd/</link>
      <pubDate>Sun, 15 Aug 2021 14:02:39 +0200</pubDate>
      
      <guid>https://netmemo.github.io/post/tf-gha-nsxt-cicd/</guid>
      <description>

&lt;p&gt;This post is to show an example of using CI/CD with Terraform Cloud and &lt;a href=&#34;https://learn.hashicorp.com/tutorials/terraform/github-actions&#34;&gt;Github Actions&lt;/a&gt; in order to have a better NetDevOps approach by doing NSX-T Network Infrastructure as code (IaC).
It&amp;rsquo;s almost a bingo, I think I have most of the buzz words of these last years :)&lt;/p&gt;

&lt;p&gt;I will describe the structure of the project, the project components, the project workflow and finish with how to test this project.&lt;/p&gt;

&lt;h1 id=&#34;structure-of-the-project&#34;&gt;Structure of the project&lt;/h1&gt;

&lt;p&gt;The diagram below shows a high level view of the &lt;a href=&#34;https://github.com/netmemo/tf-gha-nsxt-cicd&#34;&gt;project&lt;/a&gt;.
&lt;a href=&#34;tf-gha-cicd-nsx.png&#34;&gt; &lt;img src=&#34;tf-gha-cicd-nsx.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can find the file structure of the project below&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.
├─ main.tf
├─ .github
   └── workflows
       ├── dev-to-pr.yml
       ├── plan-prod.yml
       └── apply-prod.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;project-components&#34;&gt;Project components&lt;/h1&gt;

&lt;h2 id=&#34;nsx-t&#34;&gt;NSX-T&lt;/h2&gt;

&lt;p&gt;For this project we need two NSXT environments, one for production and one for development. You can either have 2 full blown NSX-T or use different variables for prod and dev or different VRFs.
In this blog post we will use two different deployments.&lt;/p&gt;

&lt;h2 id=&#34;terraform-cloud&#34;&gt;Terraform Cloud&lt;/h2&gt;

&lt;p&gt;Terraform Cloud will be used to store the state of the prod and dev environment. It will also allow to manage Terraform through APIs.
For the project we need to create 2 differents workspaces, one for production and one for developments.
The name of the workspaces should be prefix-suffix where the prefix will be what is configured in your terraform configuration file and the sufix will be what is used to select the workspace. We will cover how to select the workspace later in that post.
For this blog post, the prefix will be netmemo- and the suffix will be either prod or dev.
&lt;a href=&#34;workspaces.png&#34;&gt; &lt;img src=&#34;workspaces.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Once the workspaces are created, we need to add 3 variables for the NSX-T provider:
&lt;a href=&#34;tf-variables.png&#34;&gt; &lt;img src=&#34;tf-variables.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Finally we need to add the API key that Github Actions will use to connect to Terraform Cloud
&lt;a href=&#34;tf-token.png&#34;&gt; &lt;img src=&#34;tf-token.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;github&#34;&gt;Github&lt;/h2&gt;

&lt;p&gt;Github is where we will store the configuration and execute our CI/CD pipelines.
Once the project is forked, to make it works, we need to enable Github Actions.
&lt;a href=&#34;enable-gha.png&#34;&gt; &lt;img src=&#34;enable-gha.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Create a github &lt;a href=&#34;https://github.com/settings/tokens&#34;&gt;personal access token&lt;/a&gt; &lt;em&gt;REPO_TOKEN&lt;/em&gt;. This token will be used by Github Actions to automatically create the pull request.&lt;br /&gt;
&lt;a href=&#34;gh-perso-token.png&#34;&gt; &lt;img src=&#34;gh-perso-token.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Add the previously created token (TF_API_TOKEN and REPO_TOKEN_SECRET) to your github &lt;a href=&#34;https://github.com/netmemo/nsxt-tfc-rm/settings/secrets/actions&#34;&gt;repository secrets&lt;/a&gt;.&lt;br /&gt;
&lt;a href=&#34;repo-secret.png&#34;&gt; &lt;img src=&#34;repo-secret.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;github-actions&#34;&gt;Github Actions&lt;/h2&gt;

&lt;p&gt;This project is made from 3 scripts that form 3 pipelines. The first script will handle the dev environment. The second will handle the &lt;em&gt;terraform plan&lt;/em&gt; for the prod environments. The third will handle the &lt;em&gt;terraform apply&lt;/em&gt; for the prod environment.&lt;/p&gt;

&lt;p&gt;You can find an explanation of the main steps on the below site &lt;a href=&#34;https://learn.hashicorp.com/tutorials/terraform/github-actions&#34;&gt;Github Actions&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;dev-to-pr-yml&#34;&gt;dev-to-pr.yml&lt;/h4&gt;

&lt;p&gt;The dev-to-pr.yml Github Actions YAML file will be executed only after a &lt;em&gt;push&lt;/em&gt; on the &lt;em&gt;dev&lt;/em&gt; branch.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;on:
  push:
    branches:
      - dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first step is to checkout the current configuration.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      - name: Checkout
        uses: actions/checkout@v2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then the &lt;em&gt;Setup Terraform&lt;/em&gt; steps retrieves the Terraform CLI used in the GitHub action workflow.
This is in this step that we will use the TF_API_TOKEN that we have created previously to access Terraform Cloud from Github Actions.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          # terraform_version: 0.13.0:
          cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These following steps initialize Terraform and set the &lt;a href=&#34;https://netmemo.github.io/post/tf-workspace-var&#34;&gt;terraform workspace&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      - name: Terraform Init
        id: init
        run: terraform init
        env:
          TF_WORKSPACE: &amp;quot;dev&amp;quot;

      - name: Terraform Workspace
        id: workspace
        run: terraform workspace select dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We then validate the Terraform configuration&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      - name: Terraform Validate
        id: validate
        run: terraform validate -no-color
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This step is to execute the Terraform plan. The plan will be a speculative plan executed in Terraform Cloud. Speculative plans are not directly visible from the Terraform Cloud UI. To access it, you will need to click on the link given in the result of the Terraform plan command.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      - name: Terraform Plan
        id: plan
        run: terraform plan -no-color
        continue-on-error: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This step will execute a &lt;a href=&#34;https://github.com/marketplace/actions/github-script?version=v4.0.2&#34;&gt;github-script&lt;/a&gt; that will send a REST API query thanks to the &lt;em&gt;github&lt;/em&gt; pre-authenticated &lt;a href=&#34;https://octokit.github.io/rest.js/v18&#34;&gt;octokit/rest.js&lt;/a&gt; client with pagination plugins. It will also create a comment on the commit with the result of the previous steps.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      - uses: actions/github-script@0.9.0
        if: github.event_name == &#39;push&#39;
        env:
          PLAN: &amp;quot;terraform\n${{ steps.plan.outputs.stdout }}&amp;quot;
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const output = `#### Terraform Format and Style [36;63H\`${{ steps.fmt.outcome }}\`
            #### Terraform Initialization ⚙️\`${{ steps.init.outcome }}\`
            #### Terraform Validation [36;41H\`${{ steps.validate.outcome }}\`
            #### Terraform Plan [36;35H\`${{ steps.plan.outcome }}\`
            &amp;lt;details&amp;gt;&amp;lt;summary&amp;gt;Show Plan&amp;lt;/summary&amp;gt;
            \`\`\`\n
            ${process.env.PLAN}
            \`\`\`
            &amp;lt;/details&amp;gt;
            *Pusher: @${{ github.actor }}, Action: \`${{ github.event_name }}\`*`;
            github.repos.createCommitComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              commit_sha: context.sha,
              body: output
            })
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This step is to apply the Terraform configuration, only if the &lt;em&gt;terraform plan&lt;/em&gt; step result has succeeded.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      - name: Terraform Apply
        id: apply
        if: steps.plan.outcome == &#39;success&#39;
        run: terraform apply -auto-approve
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the &lt;em&gt;terraform apply&lt;/em&gt; succeeds, we will use the &lt;a href=&#34;https://github.com/marketplace/actions/github-script?version=v4.0.2&#34;&gt;github-script&lt;/a&gt; to create a &lt;a href=&#34;https://octokit.github.io/rest.js/v18#pulls-create&#34;&gt;Pull Request&lt;/a&gt; thanks to the &lt;a href=&#34;https://octokit.github.io/rest.js/v18&#34;&gt;octokit/rest.js&lt;/a&gt; like in the previous steps.
We will use a personal github token &lt;em&gt;PERSO_GITHUB_TOKEN&lt;/em&gt; to create the PR for these steps. If we are not using the personal token, the &lt;a href=&#34;https://github.com/peter-evans/create-pull-request/issues/48&#34;&gt;PR will not trigger other pipelines&lt;/a&gt; that have the &lt;em&gt;on:pull_request trigger&lt;/em&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      - name: CreatePR if apply succeed
        uses: actions/github-script@v4.0.2
        if: steps.apply.outcome == &#39;success&#39;
        with:
          github-token: ${{ secrets.PERSO_GITHUB_TOKEN }}
          script: |
            github.pulls.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: &amp;quot;Auto PR&amp;quot;,
              head: &amp;quot;dev&amp;quot;,
              base: &amp;quot;main&amp;quot;
            });
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;plan-prod-yml&#34;&gt;plan-prod.yml&lt;/h4&gt;

&lt;p&gt;The plan-prod.yml Github Actions YAML file will be executed only after a &lt;em&gt;pull request&lt;/em&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;on:
  pull_request:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Most of the steps have already been described for the &lt;em&gt;dev-to-pr.yml&lt;/em&gt; files, the only difference is the step below.
It will add a comment on the PR with the description of what has been done.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      - uses: actions/github-script@v4.0.2
        env:
          PLAN: &amp;quot;terraform\n${{ steps.plan.outputs.stdout }}&amp;quot;
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const output = `#### Terraform Initialization ⚙️\`${{ steps.init.outcome }}\`
            #### Terraform Validation [36;41H\`${{ steps.validate.outcome }}\`
            #### Terraform Plan [36;35H\`${{ steps.plan.outcome }}\`
            &amp;lt;details&amp;gt;&amp;lt;summary&amp;gt;Show Plan&amp;lt;/summary&amp;gt;
            \`\`\`\n
            ${process.env.PLAN}
            \`\`\`
            &amp;lt;/details&amp;gt;
            *Pusher: @${{ github.actor }}, Action: \`${{ github.event_name }}\`*`;
            github.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: output
            })
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;apply-prod-yml&#34;&gt;apply-prod.yml&lt;/h4&gt;

&lt;p&gt;The plan-prod.yml Github Actions YAML file will be executed only after a &lt;em&gt;push&lt;/em&gt; on the main branch.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;on:
  push:
    branches:
      - main
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The other steps have already been discussed previously.&lt;/p&gt;

&lt;h2 id=&#34;terraform-file&#34;&gt;Terraform file&lt;/h2&gt;

&lt;p&gt;For this blog post we will have a single main.tf file.
This Terraform script should have the terraform configuration, the provider definition and the resources definitions.&lt;/p&gt;

&lt;h4 id=&#34;terraform-variables&#34;&gt;Terraform variables&lt;/h4&gt;

&lt;p&gt;This is where we declare the Terraform variables that will be defined in the Terrafrom Cloud workspaces. These variables will change according to the environment.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;variable &amp;quot;password&amp;quot; {
  type = string
}
variable &amp;quot;username&amp;quot; {
  type = string
}
variable &amp;quot;nsxhost&amp;quot; {
  type = string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;terraform-configuration-section&#34;&gt;Terraform configuration section&lt;/h4&gt;

&lt;p&gt;In this section we are setting the 2 providers needed and the backend.
The &lt;em&gt;backend &amp;ldquo;&lt;a href=&#34;https://www.terraform.io/docs/language/settings/backends/remote.html#workspaces&#34;&gt;remote&lt;/a&gt;&amp;ldquo;&lt;/em&gt; is where you find the Terraform Cloud organization and workspaces prefixes.
The workspaces suffixes will be added as seen in the beginning of this post with the &lt;a href=&#34;https://learn.hashicorp.com/tutorials/terraform/automate-terraform?in=terraform/automation&#34;&gt;TF_WORKSPACE&lt;/a&gt; environment variables and the &lt;a href=&#34;https://www.terraform.io/docs/language/settings/backends/remote.html#workspaces&#34;&gt;terraform workspace select&lt;/a&gt; command in the Github Actions steps.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;terraform {
  required_providers {
    random = {
      source = &amp;quot;hashicorp/random&amp;quot;
      version = &amp;quot;3.0.1&amp;quot;
    }
    nsxt = {
      source = &amp;quot;vmware/nsxt&amp;quot;
      version = &amp;quot;&amp;gt;= 3.1.1&amp;quot;
    }
  }

  backend &amp;quot;remote&amp;quot; {
    organization = &amp;quot;netmemo&amp;quot;

    workspaces {
      prefix = &amp;quot;netmemo-&amp;quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;provider-configuration&#34;&gt;Provider configuration&lt;/h4&gt;

&lt;p&gt;This is the NSX-T provider configuration. We pass the 3 variables that are defined in the Terraform Cloud workspaces.
We disable the SSL verification because this is a local lab.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;provider &amp;quot;nsxt&amp;quot; {
    host = var.nsxhost
    username = var.username
    password = var.password
    allow_unverified_ssl = true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;resource-creation&#34;&gt;Resource creation&lt;/h4&gt;

&lt;p&gt;For this blog post we will create a &lt;a href=&#34;https://registry.terraform.io/providers/vmware/nsxt/latest/docs/resources/policy_tier1_gateway&#34;&gt;NSX-T T1 gateway&lt;/a&gt; name &lt;strong&gt;T1-TFC&lt;/strong&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;nsxt_policy_tier1_gateway&amp;quot; &amp;quot;tier1_gw&amp;quot; {
  description               = &amp;quot;Tier-1 provisioned by Terraform&amp;quot;
  display_name              = &amp;quot;T1-TFC&amp;quot;
  route_advertisement_types = [&amp;quot;TIER1_CONNECTED&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;project-workflow&#34;&gt;Project workflow&lt;/h1&gt;

&lt;p&gt;Clic the arrows to see the detail.
&lt;details&gt;
&lt;summary&gt;1. Modify the dev branch on you local git.&lt;/summary&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;2. Add the modif to git, commit them and push the dev branch to your github repo.&lt;/summary&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git add .

git commit -am &amp;quot;add T1-GW&amp;quot;
[dev a0b946b] add T1-GW
 2 files changed, 6 insertions(+), 6 deletions(-)

git push
Counting objects: 6, done.
Delta compression using up to 2 threads.
Compressing objects: 100% (5/5), done.
Writing objects: 100% (6/6), 617 bytes | 617.00 KiB/s, done.
Total 6 (delta 2), reused 0 (delta 0)
remote: Resolving deltas: 100% (2/2), completed with 2 local objects.
To ssh://github.com/netmemo/tf-gha-nsxt-cicd.git
   8534543..a0b946b  dev -&amp;gt; dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;3. Dev pipeline&lt;/summary&gt;
The dev pipeline is triggered, you can see it&amp;rsquo;s starting in the Actions tab. It&amp;rsquo;s tittle will be the commit message.&lt;br /&gt;
&lt;a href=&#34;workflow-start.png&#34;&gt; &lt;img src=&#34;workflow-start.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;
To validate that the dev pipeline is completed, you can check the Terraform cloud dev workspace state and the NSX-T dev environment to see that there is a new T1-GW.
&lt;a href=&#34;tfc-state-dev-after.png&#34;&gt; &lt;img src=&#34;tfc-state-dev-after.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;4. Integration pipeline&lt;/summary&gt;
After all the steps in the dev pipeline are passed, the workflow will turn green. The last step of the pipeline will create an automatic PR that will trigger the integration pipeline. This pipeline will validate the configuration and creates a plan against the production environment.
The PR will have the description &lt;strong&gt;&amp;ldquo;Auto PR generate by Github Action dev pipeline&amp;rdquo;&lt;/strong&gt;
&lt;a href=&#34;pr-list.png&#34;&gt; &lt;img src=&#34;pr-list.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;
The integration pipeline will execute the &lt;em&gt;terraform plan&lt;/em&gt; command against the production environment. You can then check again the Actions tab to see that the development and integration pipeline has turned green.
&lt;a href=&#34;workflow-2-pipeline-ok.png&#34;&gt; &lt;img src=&#34;workflow-2-pipeline-ok.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;
If the two pipelines are ok, the checks in the PR should be green.&lt;br /&gt;
&lt;a href=&#34;\pr-test-ok.png&#34;&gt; &lt;img src=&#34;pr-test-ok.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;5. Merge&lt;/summary&gt;
When the dev and integration pipeline are finished, the dev branch is ready to be merged to the main branch. You can then clic on the &lt;strong&gt;Merge pull request&lt;/strong&gt; button to validate the merge and trigger the deployment pipeline.
&lt;a href=&#34;going-to-prod.png&#34;&gt; &lt;img src=&#34;going-to-prod.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;
&lt;a href=&#34;pr-merged.png&#34;&gt; &lt;img src=&#34;pr-merged.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;6. Deployment pipeline&lt;/summary&gt;
The deployment pipeline is triggered with the push/merge to the main branch. This is the final workflow that will push the Terraform configuration to production. You can see in Terraform Cloud that Terraform is applying the configuration.
&lt;a href=&#34;tfc-prod-applying.png&#34;&gt; &lt;img src=&#34;tfc-prod-applying.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;
You can now double check in Github Actions that the deployment workflow has been succefully executed, &lt;strong&gt;&amp;ldquo;Merge pull request #10&amp;rdquo;&lt;/strong&gt; in the picture below.
&lt;a href=&#34;pipeline-apply-ok-list.png&#34;&gt; &lt;img src=&#34;pipeline-apply-ok-list.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;7. Checks&lt;/summary&gt;
Finally you can now verify that there is a resource on Terraform Cloud and that the T1 Gateway has been created on the production NSX-T.&lt;br /&gt;
&lt;a href=&#34;tfc-prod-ok.png&#34;&gt; &lt;img src=&#34;tfc-prod-ok.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;
&lt;a href=&#34;nsxt-prod-ok.png&#34;&gt; &lt;img src=&#34;nsxt-prod-ok.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;
&lt;/details&gt;&lt;/p&gt;

&lt;h1 id=&#34;how-to-test-this-project&#34;&gt;How to test this project.&lt;/h1&gt;

&lt;p&gt;Requirements:&lt;br /&gt;
- NSX-T environment (there are examples on the web to use AWS as provider instead of NSX, the concepts are the same).&lt;br /&gt;
- Terraform Cloud account with 2 workspaces.&lt;br /&gt;
- Github account and git locally.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;[NSX-T]&lt;/strong&gt; Prepare your two NSX-T environments.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TFC]&lt;/strong&gt; Create your two workspaces in TFC with the API Key for Github.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[GITHUB]&lt;/strong&gt; Fork this &lt;a href=&#34;https://github.com/netmemo/tf-gha-nsxt-cicd&#34;&gt;project&lt;/a&gt;, add the TFC API key and your personal API Key to your repo, enable actions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[LOCAL]&lt;/strong&gt; Clone your forked project to your local git.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[LOCAL]&lt;/strong&gt; Create the dev branch locally.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[LOCAL]&lt;/strong&gt; Modify the Terraform configuration in the main.tf according to your TFC workspace.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[LOCAL]&lt;/strong&gt; Add to git, commit, push.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[GITHUB]&lt;/strong&gt; Wait until all the test pass.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[GITHUB]&lt;/strong&gt; Click merge to deploy to prod.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;pain-points-of-the-project&#34;&gt;Pain points of the project.&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Switching &lt;a href=&#34;https://netmemo.github.io/post/tf-workspace-var&#34;&gt;terraform workspace&lt;/a&gt; with github actions.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Create &lt;a href=&#34;https://netmemo.github.io/post/gha-auto-pr&#34;&gt;automatically&lt;/a&gt; a github PR with with rest.js API of octokit.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;script src=&#34;https://utteranc.es/client.js&#34;
        repo=&#34;[ENTER REPO HERE]&#34;
        issue-term=&#34;pathname&#34;
        theme=&#34;github-dark&#34;
        crossorigin=&#34;anonymous&#34;
        async&gt;
&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>Triggering Github Actions workflow with automatic Pull Request</title>
      <link>https://netmemo.github.io/post/gha-auto-pr/</link>
      <pubDate>Thu, 12 Aug 2021 17:01:57 +0200</pubDate>
      
      <guid>https://netmemo.github.io/post/gha-auto-pr/</guid>
      <description>&lt;p&gt;This post is to explain one of the pain point I have encountered while trying to do &lt;a href=&#34;https://netmemo.github.io/post/tf-gha-nsxt-cicd&#34;&gt;Github Actions with Terraform Cloud for CI/CD of NSX-T&lt;/a&gt;.
The difficulty is to chain workflow/pipeline automatically. In my case, I wanted to launch a workflow base of a PR create by another workflow.
When you use Github Actions to interface with Github, you need to authenticate your Github Actions script against Github.
You can then use the &lt;a href=&#34;https://docs.github.com/en/actions/reference/authentication-in-a-workflow&#34;&gt;GITHUB_TOKEN&lt;/a&gt; that has been made for this purpose. As this token is known from Github to be automation token, to avoid loops, you can use it to create a PR to trigger another workflow.
The workaround to this [known limitation] is to create the PR with a personal access token.&lt;/p&gt;

&lt;p&gt;You can find below an example of using the personal access token to create a PR. To create the &lt;a href=&#34;https://octokit.github.io/rest.js/v18#pulls-create&#34;&gt;Pull Request&lt;/a&gt; we are using &lt;a href=&#34;https://github.com/marketplace/actions/github-script?version=v4.0.2&#34;&gt;github-script&lt;/a&gt; that will send a REST API query thanks to the &lt;em&gt;github&lt;/em&gt; pre-authenticated &lt;a href=&#34;https://octokit.github.io/rest.js/v18&#34;&gt;octokit/rest.js&lt;/a&gt; client with pagination plugins.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      - name: CreatePR if apply succeed
        uses: actions/github-script@v4.0.2
        if: steps.apply.outcome == &#39;success&#39;
        with:
          github-token: ${{ secrets.PERSO_GITHUB_TOKEN }}
          script: |
            github.pulls.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: &amp;quot;Auto PR&amp;quot;,
              head: &amp;quot;dev&amp;quot;,
              base: &amp;quot;main&amp;quot;
            });
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Changing Terraform Cloud workspace in Github Actions</title>
      <link>https://netmemo.github.io/post/tf-workspace-var/</link>
      <pubDate>Thu, 12 Aug 2021 15:22:40 +0200</pubDate>
      
      <guid>https://netmemo.github.io/post/tf-workspace-var/</guid>
      <description>&lt;p&gt;This blog post is to explain how I did to automatically change Terraform Cloud workspace from Github Actions.
As explained in the documentation &lt;a href=&#34;https://www.terraform.io/docs/language/settings/backends/remote.html#workspaces&#34;&gt;remote workspace&lt;/a&gt;, you can use different remote workspace by specifying the prefix of you workspace in the Terraform backend configuration.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  backend &amp;quot;remote&amp;quot; {
    organization = &amp;quot;netmemo&amp;quot;

    workspaces {
      prefix = &amp;quot;netmemo-&amp;quot;
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After that, you only need to select the proper workspace by entering the &lt;em&gt;terraform workspace select [suffix]&lt;/em&gt; command.
The issue comes if you want to do it in a fully automated environment like with Github Actions. You need an extra step which is to set the &lt;a href=&#34;https://learn.hashicorp.com/tutorials/terraform/automate-terraform?in=terraform/automation&#34;&gt;TF_WORKSPACE&lt;/a&gt; variable.&lt;/p&gt;

&lt;p&gt;Below are the 2 steps that are needed to select a specific environment.
In this blog the workspace will be netmemo-dev where netmemo- is the prefix configured in the main.tf and dev the suffix configured in the .yml file of the Github Actions script.&lt;/p&gt;

&lt;p&gt;This step initializes Terraform and set the TF_WORKSPACE variable to indicate that we want to use the dev environment suffix before the initialization.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      - name: Terraform Init
        id: init
        run: terraform init
        env:
          TF_WORKSPACE: &amp;quot;dev&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we are not setting the &lt;a href=&#34;https://learn.hashicorp.com/tutorials/terraform/automate-terraform?in=terraform/automation&#34;&gt;TF_WORKSPACE&lt;/a&gt;, the init command will try to get the default workspace that doesn&amp;rsquo;t exist and you will have the following error.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The currently selected workspace (default) does not exist.
  This is expected behavior when the selected workspace did not have an
  existing non-empty state. Please enter a number to select a workspace:
  
  1. dev
  2. prod
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Even after setting the &lt;a href=&#34;https://learn.hashicorp.com/tutorials/terraform/automate-terraform?in=terraform/automation&#34;&gt;TF_WORKSPACE&lt;/a&gt; variable, we still need to enter the &lt;em&gt;terraform workspace select&lt;/em&gt; command to provide the suffix of the workspace.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      - name: Terraform Workspace
        id: workspace
        run: terraform workspace select dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we forgot to enter the command to select workspace, the Terraform configuration section will try to load a workspace with only the prefix and trigger an error.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error: error starting operation: The configured &amp;quot;remote&amp;quot; backend encountered an unexpected error:

invalid value for workspace
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can find a full example of where we need to change workspace automatically in this blog post &lt;a href=&#34;https://netmemo.github.io/post/tf-gha-nsxt-cicd&#34;&gt;Github Actions with Terraform Cloud for CI/CD of NSX-T&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NSX-T Firewall rules as code with Terraform</title>
      <link>https://netmemo.github.io/post/nsxt-tf-firewall/</link>
      <pubDate>Thu, 29 Jul 2021 19:03:37 +0200</pubDate>
      
      <guid>https://netmemo.github.io/post/nsxt-tf-firewall/</guid>
      <description>

&lt;p&gt;This article is to show an example of how to manage NSX-T firewall rules as a code through Terraform.
You can find the project on my github account : &lt;a href=&#34;https://github.com/netmemo/nsxt-frac-tf-cm&#34;&gt;nsxt-frac-tf-cm&lt;/a&gt; and &lt;a href=&#34;https://github.com/netmemo/nsxt-frac-tf-rm&#34;&gt;nsxt-frac-tf-rm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I will describe the structure of the project, how it works, the data model, the Terraform code explanation and finish with an example.&lt;/p&gt;

&lt;h1 id=&#34;structure-of-the-project&#34;&gt;Structure of the project&lt;/h1&gt;

&lt;p&gt;The diagram below shows a summary of how I organized the project in order to fully use infrastructre as code.&lt;br /&gt;
&lt;a href=&#34;nsxt-tf-firewall.png&#34;&gt; &lt;img src=&#34;nsxt-tf-firewall.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Below is the file structure&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#Child modules

├── nsxt-frac-tf-cm 
    ├── nsxt-tf-cm-dfw
    │   ├── main.tf
    │   ├── outputs.tf
    │   └── variables.tf
    ├── nsxt-tf-cm-grp
    │   ├── main.tf
    │   ├── outputs.tf
    │   └── variables.tf
    └── nsxt-tf-cm-svc
        ├── main.tf
        ├── outputs.tf
        └── variables.tf

#Root modules

├── nsxt-frac-tf-rm
    ├── nsxt-tf-rm-dfw
    │   ├── main.tf
    │   ├── provider.tf
    │   ├── terraform.tfvars
    │   └── variables.tf
    └── nsxt-tf-rm-grpsvc
        ├── main.tf
        ├── outputs.tf
        ├── provider.tf
        ├── terraform.tfvars
        └── variables.tf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In short, child modules are the logic, root modules are the variables.&lt;br /&gt;
You can then duplicate the root module according to the NSX-T environment you want to deploy and start using the variables for the environment.&lt;/p&gt;

&lt;h1 id=&#34;how-it-works&#34;&gt;How it works&lt;/h1&gt;

&lt;h2 id=&#34;child-module&#34;&gt;Child Module&lt;/h2&gt;

&lt;p&gt;You can find the logics and the code complexity in the Terraform child modules.&lt;br /&gt;
They will create the NSX-T resources. They allow to centralize the complexity. If you need to change your logic, you only need to modify the child module.&lt;br /&gt;
After the modification, from the root module you only need to pull the new modifications by reinitializing or refreshing the modules with &amp;ldquo;terraform init&amp;rdquo; and then you can start using the new features.&lt;/p&gt;

&lt;p&gt;There are tree child modules:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;nsxt-tf-cm-svc&lt;br /&gt;
This is for the NSX-T (TCP/UDP/IP) services creation&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;nsxt-tf-cm-grp&lt;br /&gt;
This is for the NSX-T (TAG and IP) groups creation&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;nsxt-tf-cm-dfw&lt;br /&gt;
This is for the NSX-T policy and rules creation&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;root-module&#34;&gt;Root Module&lt;/h2&gt;

&lt;p&gt;It will call the child module with the variables associated with the NSX-T environment. You need to create a repository per environment. The only modifications you need to do is to change the variables.&lt;br /&gt;
The root module can be declined to different NSX-T environments/deployments as long as the variable structure used in the root module respects the child module data model.&lt;/p&gt;

&lt;p&gt;Root modules are separated in two :&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;nsxt-tf-rm-grpsvc&lt;/strong&gt;&lt;br /&gt;
This module will call the groups and the services child module an pass them the groups and services&amp;rsquo;s map variables.
As the groups and services can be centralized and be the same for all environments, I have prefered to managed them separatly from the policies and rules.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;nsxt-tf-rm-dfw&lt;/strong&gt;&lt;br /&gt;
This is the policies and rules definition. This root module will use the terraform state output section of the root module &lt;em&gt;nsxt-tf-rm-grpsvc&lt;/em&gt; to get all the groups and services needed.
The &lt;em&gt;output.tf&lt;/em&gt; file is defined in &lt;em&gt;nsxt-tf-rm-grpsvc&lt;/em&gt; root module.&lt;/p&gt;

&lt;h1 id=&#34;data-model&#34;&gt;Data model&lt;/h1&gt;

&lt;p&gt;To have more details of the possible attributes used, you can refer to the NSX-T Terraform official &lt;a href=&#34;https://registry.terraform.io/providers/vmware/nsxt/latest/docs&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;services&#34;&gt;Services&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;map_svc&lt;/strong&gt;&lt;br /&gt;
This is the map variable passed to the child module.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;This variable is a map of services map where the name is the service name&lt;/li&gt;
&lt;li&gt;Every service name contains lists.&lt;/li&gt;
&lt;li&gt;Every list name is the service type (IP, TCP or UDP).&lt;/li&gt;
&lt;li&gt;Every list is either a protocol number if the list is IP or port number if the list is TCP/UDP&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;map_svc = {
   NETMEMO-ESP = { IP = [&amp;quot;50&amp;quot;] }
   NETMEMO-NETBIOS = { TCP = [&amp;quot;135&amp;quot;,&amp;quot;137&amp;quot;,&amp;quot;139&amp;quot;,&amp;quot;139&amp;quot;], UDP = [&amp;quot;135&amp;quot;,&amp;quot;137&amp;quot;,&amp;quot;139&amp;quot;,&amp;quot;139&amp;quot;] }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;groups&#34;&gt;Groups&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;map_grp&lt;/strong&gt;&lt;br /&gt;
This is the map variable passed to the child module.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;This variable is a map of groups map where the name is the group name.&lt;/li&gt;
&lt;li&gt;Every group name contains lists.&lt;/li&gt;
&lt;li&gt;Every list name is the group type (IP or TAG).&lt;/li&gt;
&lt;li&gt;Every list is either subnet if the list is IP or tag name if the list is TAG&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;map_grp = {
   NETMEMO-LOCAL = { IP = [&amp;quot;10.0.0.0/25&amp;quot;,&amp;quot;10.1.1.0/25&amp;quot;] }
   NETMEMO-NAS = { TAG = [&amp;quot;NAS&amp;quot;,&amp;quot;FILES&amp;quot;] }
   NETMEMO-ESX = { TAG = [&amp;quot;ESX&amp;quot;,&amp;quot;VMWARE&amp;quot;] }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;policies&#34;&gt;Policies&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;map_policies&lt;/strong&gt;&lt;br /&gt;
This is the map variable passed to the child module.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;This variable is a map of policy map where the name is the policy name.&lt;/li&gt;
&lt;li&gt;Every policy name contains different attributes that are either string or map. The map named &amp;ldquo;rules&amp;rdquo; is to define the rules.&lt;/li&gt;
&lt;li&gt;Every &amp;ldquo;rules&amp;rdquo; map contains maps to define rules. Every map is a rule.&lt;/li&gt;
&lt;li&gt;Every rule map contains stings and list attrubutes (sources,destinations,services,scope)&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;map_policies = {
   NETMEMO-POL1 = {
      category = &amp;quot;Application&amp;quot;
	  sequence_number = &amp;quot;10&amp;quot;
	  rules = {
	     netmemo-rule1 = {
		    display = &amp;quot;NETMEMO-NAS-R&amp;quot;
			sources = [&amp;quot;NETMEMO-NAS&amp;quot;]
			destinations = [&amp;quot;NETMEMO-NAS&amp;quot;]
			services = [&amp;quot;HTTPS&amp;quot;]
			scope = [&amp;quot;NETMEMO-NAS&amp;quot;]
			action = &amp;quot;ALLOW&amp;quot;
			disabled = &amp;quot;false&amp;quot;
	     }
	     netmemo-rule2 = {
		    display = &amp;quot;NETMEMO-ESX-R&amp;quot;
			sources = [&amp;quot;NETMEMO-ESX&amp;quot;]
			destinations = [&amp;quot;NETMEMO-ESX&amp;quot;]
			services = [&amp;quot;HTTPS&amp;quot;]
			scope = [&amp;quot;NETMEMO-ESX&amp;quot;]
			action = &amp;quot;ALLOW&amp;quot;
			disabled = &amp;quot;false&amp;quot;
	     }
	  }
   }
   NETMEMO-POL2 = {
      category = &amp;quot;Application&amp;quot;
	  sequence_number = &amp;quot;20&amp;quot;
	  rules = {
	     netmemo-rule1 = {
		    display = &amp;quot;NETMEMO-LOCAL-R&amp;quot;
			sources = [&amp;quot;NETMEMO-LOCAL&amp;quot;]
			destinations = [&amp;quot;NETMEMO-NAS&amp;quot;,&amp;quot;NETMEMO-ESX&amp;quot;]
			services = [&amp;quot;NETMEMO-NETBIOS&amp;quot;,&amp;quot;HTTPS&amp;quot;]
			scope = [&amp;quot;NETMEMO-NAS&amp;quot;,&amp;quot;NETMEMO-ESX&amp;quot;]
			action = &amp;quot;ALLOW&amp;quot;
			disabled = &amp;quot;false&amp;quot;
	     }
	  }
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;code-explanation&#34;&gt;Code Explanation&lt;/h1&gt;

&lt;h2 id=&#34;root-module-1&#34;&gt;Root Module&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;nsxt-tf-cm-grp and nsxt-tf-cm-svc child modules&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;These child modules use nested for_each with conditional nested dynamic.&lt;br /&gt;
A brief example of the nested for_each used with dynamic can be found &lt;a href=&#34;https://netmemo.github.io/post/tf-nsxt-nested-for-each/&#34;&gt;here&lt;/a&gt;. The conditional behavior is done thanks to the filter of the for loop. You can find the documentation on this &lt;a href=&#34;https://www.terraform.io/docs/language/expressions/for.html&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dynamic terraform blocks allow to create a block for all the elements in the map you give to the for_each loop. In our child modules, the element of the dynamic for_each loop are also filtered with a for loop and a if.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If the map contains a TAG attribute we create the &lt;em&gt;criteria&lt;/em&gt; block with the TAG attributes.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dynamic &amp;quot;criteria&amp;quot; {
#The for_each contains a for loop with filter to create the criteriia only if there is a list with the name TAG
for_each = { for key,val in each.value : key =&amp;gt; val if key == &amp;quot;TAG&amp;quot; }
  content {
     dynamic &amp;quot;condition&amp;quot; {
        #looping over the set to create every tags
        for_each = criteria.value

        content {
           key = &amp;quot;Tag&amp;quot;
           member_type = &amp;quot;VirtualMachine&amp;quot;
           operator = &amp;quot;EQUALS&amp;quot;
           value = condition.value
        }
     }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If the map contains a IP attribute we create the &lt;em&gt;criteria&lt;/em&gt; block with the IP attributes.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dynamic &amp;quot;criteria&amp;quot; {
#The for_each contains a for loop with filter to create the criteriia only if there is a list with the name IP
for_each = { for key,val in each.value : key =&amp;gt; val if key == &amp;quot;IP&amp;quot; }
  content {
     ipaddress_expression  {
        ip_addresses = criteria.value
     }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The same logic is used to create services.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If the map contains a TCP or UDP attribute we create the &lt;em&gt;l4_port_set_entry block&lt;/em&gt; with the TCP/UDP attributes.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dynamic &amp;quot;l4_port_set_entry&amp;quot; {
  #each.value = map of TCP,UDP or IP list where l4_port_set_entry.key will be TCP or UDP
  #the for_each contains a for loop with filter to create the l4_port_set_entry only if there is a list with TCP or UDP as name
  for_each = { for key,val in each.value : key =&amp;gt; val if key == &amp;quot;TCP&amp;quot; || key == &amp;quot;UDP&amp;quot; }
      content {
         display_name = &amp;quot;${l4_port_set_entry.key}_${each.key}&amp;quot;
         protocol = l4_port_set_entry.key
         destination_ports = l4_port_set_entry.value
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If the map contains a IP attribute we create the &lt;em&gt;ip_protocol_entry block&lt;/em&gt; with the IP attributes.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dynamic &amp;quot;ip_protocol_entry&amp;quot; {
  #each.value = map of TCP,UDP or IP list 
  #the for_each contains a for loop with filter to create the ip_protocol_entry only if there is a list with IP as name
  for_each = { for key,val in each.value : key =&amp;gt; val if key == &amp;quot;IP&amp;quot; }
      content {
         #[0] because the ip protocol will have a single IP protocol value in the set and the protocol attribut expect a number not a set
         protocol = ip_protocol_entry.value[0]
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;nsxt-tf-cm-dfw child modules&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The complexity of this module is to get the NSX-T &amp;ldquo;Path&amp;rdquo; attributes of the groups and services with their name defined in their respective map variable.
We want the map variables definition of the policies and rules to be as much friendly as possible and not dependant of values specific to the NSX-T implementation (path).
This will also allow us to reuse the policies variables values in other environments if the rules are generic for instance.&lt;/p&gt;

&lt;p&gt;In order to retreive the value we are looping over the &amp;ldquo;list&amp;rdquo; in the group or service attribute and &amp;ldquo;try&amp;rdquo; to get the path attribute.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;source_groups = [for x in rule.value[&amp;quot;sources&amp;quot;] : try(var.nsxt_policy_grp_grp[x].path)]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;child-module-1&#34;&gt;Child Module&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;nsxt-tf-rm-grpsvc&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is how to use a child module stored in git within a root module.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module &amp;quot;nsxt-tf-cm-svc&amp;quot; {
   source = &amp;quot;git::https://github.com/netmemo/nsxt-frac-tf-cm.git//nsxt-tf-cm-svc&amp;quot;
   map_svc = var.map_svc
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Below is the code of the &lt;em&gt;output.tf&lt;/em&gt; file that adds the groups and service maps into the terraform.state output section. It will allow other root modules to use these variables as &lt;em&gt;terraform_remote_state&lt;/em&gt; datasource.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;output &amp;quot;grp&amp;quot; {
   value = module.nsxt-tf-cm-grp.grp
}

output &amp;quot;svc&amp;quot; {
   value = module.nsxt-tf-cm-svc.svc
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;nsxt-tf-rm-dfw&lt;/strong&gt;&lt;br /&gt;
Below is the code to refer to a remote state, in this case the remote state is local.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data &amp;quot;terraform_remote_state&amp;quot; &amp;quot;grpsvc&amp;quot; {
   backend = &amp;quot;local&amp;quot;
   
   config = {
      path = &amp;quot;../nsxt-tf-rm-grpsvc/terraform.tfstate&amp;quot;
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;demo&#34;&gt;Demo&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Requirement:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Terraform 0.14+&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;NSX-T 3.0.2+&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Clone the root module &lt;a href=&#34;https://github.com/netmemo/nsxt-frac-tf-rm&#34;&gt;nsxt-frac-tf-rm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To make a test, you need to follow the steps below (clic to see the detail):&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
&lt;summary&gt;1. Clone the root module repo&lt;/summary&gt;
&lt;strong&gt;git clone git@github.com:netmemo/nsxt-frac-tf-rm.git&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Cloning into &#39;nsxt-frac-tf-rm&#39;...
remote: Enumerating objects: 21, done.
remote: Counting objects: 100% (21/21), done.
remote: Compressing objects: 100% (15/15), done.
remote: Total 21 (delta 7), reused 20 (delta 6), pack-reused 0
Receiving objects: 100% (21/21), done.
Resolving deltas: 100% (7/7), done.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;2.Move to the cloned repo&lt;/summary&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd your directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;3.Initialize terraform&lt;/summary&gt;
&lt;strong&gt;terraform init&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Initializing modules...
Downloading git::https://github.com/netmemo/nsxt-frac-tf-cm.git for nsxt-tf-cm-dfw...
- nsxt-tf-cm-dfw in .terraform/modules/nsxt-tf-cm-dfw/nsxt-tf-cm-dfw

Initializing the backend...

Initializing provider plugins...
- terraform.io/builtin/terraform is built in to Terraform
- Finding vmware/nsxt versions matching &amp;quot;&amp;gt;= 3.1.1&amp;quot;...
- Installing vmware/nsxt v3.2.2...
- Installed vmware/nsxt v3.2.2 (signed by a HashiCorp partner, key ID 6B6B0F38607A2264)

Partner and community providers are signed by their developers.
If you&#39;d like to know more about provider signing, you can read about it here:
https://www.terraform.io/docs/cli/plugins/signing.html

Terraform has created a lock file .terraform.lock.hcl to record the provider
selections it made above. Include this file in your version control repository
so that Terraform can guarantee to make the same selections by default when
you run &amp;quot;terraform init&amp;quot; in the future.

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running &amp;quot;terraform plan&amp;quot; to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;4.Edit the provider.tf file&lt;/summary&gt;
Change the host, the username and password according to your environment.
You need to either add the variable in the terraform.tfvars file or enter them when the prompt will ask you.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;provider &amp;quot;nsxt&amp;quot; {
   host = var.host
   username = &amp;quot;admin&amp;quot;
   password = var.password
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;5.Create the group and services&lt;/summary&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;terraform plan -out plan.out&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following
symbols:
  + create

Terraform will perform the following actions:

  # module.nsxt-tf-cm-grp.nsxt_policy_group.grp[&amp;quot;NETMEMO-ESX&amp;quot;] will be created
  + resource &amp;quot;nsxt_policy_group&amp;quot; &amp;quot;grp&amp;quot; {
      + display_name = &amp;quot;NETMEMO-ESX&amp;quot;
      + domain       = &amp;quot;default&amp;quot;
      + id           = (known after apply)
      + nsx_id       = (known after apply)
      + path         = (known after apply)
      + revision     = (known after apply)

      + criteria {
          + condition {
              + key         = &amp;quot;Tag&amp;quot;
              + member_type = &amp;quot;VirtualMachine&amp;quot;
              + operator    = &amp;quot;EQUALS&amp;quot;
              + value       = &amp;quot;ESX&amp;quot;
            }
          + condition {
              + key         = &amp;quot;Tag&amp;quot;
              + member_type = &amp;quot;VirtualMachine&amp;quot;
              + operator    = &amp;quot;EQUALS&amp;quot;
              + value       = &amp;quot;VMWARE&amp;quot;
            }
        }
    }

  # module.nsxt-tf-cm-grp.nsxt_policy_group.grp[&amp;quot;NETMEMO-LOCAL&amp;quot;] will be created
  + resource &amp;quot;nsxt_policy_group&amp;quot; &amp;quot;grp&amp;quot; {
      + display_name = &amp;quot;NETMEMO-LOCAL&amp;quot;
      + domain       = &amp;quot;default&amp;quot;
      + id           = (known after apply)
      + nsx_id       = (known after apply)
      + path         = (known after apply)
      + revision     = (known after apply)

      + criteria {

          + ipaddress_expression {
              + ip_addresses = [
                  + &amp;quot;10.0.0.0/25&amp;quot;,
                  + &amp;quot;10.1.1.0/25&amp;quot;,
                ]
            }
        }
    }

  # module.nsxt-tf-cm-grp.nsxt_policy_group.grp[&amp;quot;NETMEMO-NAS&amp;quot;] will be created
  + resource &amp;quot;nsxt_policy_group&amp;quot; &amp;quot;grp&amp;quot; {
      + display_name = &amp;quot;NETMEMO-NAS&amp;quot;
      + domain       = &amp;quot;default&amp;quot;
      + id           = (known after apply)
      + nsx_id       = (known after apply)
      + path         = (known after apply)
      + revision     = (known after apply)

      + criteria {
          + condition {
              + key         = &amp;quot;Tag&amp;quot;
              + member_type = &amp;quot;VirtualMachine&amp;quot;
              + operator    = &amp;quot;EQUALS&amp;quot;
              + value       = &amp;quot;NAS&amp;quot;
            }
          + condition {
              + key         = &amp;quot;Tag&amp;quot;
              + member_type = &amp;quot;VirtualMachine&amp;quot;
              + operator    = &amp;quot;EQUALS&amp;quot;
              + value       = &amp;quot;FILES&amp;quot;
            }
        }
    }

  # module.nsxt-tf-cm-svc.nsxt_policy_service.svc[&amp;quot;NETMEMO-ESP&amp;quot;] will be created
  + resource &amp;quot;nsxt_policy_service&amp;quot; &amp;quot;svc&amp;quot; {
      + display_name = &amp;quot;NETMEMO-ESP&amp;quot;
      + id           = (known after apply)
      + nsx_id       = (known after apply)
      + path         = (known after apply)
      + revision     = (known after apply)

      + ip_protocol_entry {
          + protocol = 50
        }
    }

  # module.nsxt-tf-cm-svc.nsxt_policy_service.svc[&amp;quot;NETMEMO-NETBIOS&amp;quot;] will be created
  + resource &amp;quot;nsxt_policy_service&amp;quot; &amp;quot;svc&amp;quot; {
      + display_name = &amp;quot;NETMEMO-NETBIOS&amp;quot;
      + id           = (known after apply)
      + nsx_id       = (known after apply)
      + path         = (known after apply)
      + revision     = (known after apply)

      + l4_port_set_entry {
          + destination_ports = [
              + &amp;quot;135&amp;quot;,
              + &amp;quot;137&amp;quot;,
              + &amp;quot;139&amp;quot;,
            ]
          + display_name      = &amp;quot;TCP_NETMEMO-NETBIOS&amp;quot;
          + protocol          = &amp;quot;TCP&amp;quot;
          + source_ports      = []
        }
      + l4_port_set_entry {
          + destination_ports = [
              + &amp;quot;135&amp;quot;,
              + &amp;quot;137&amp;quot;,
              + &amp;quot;139&amp;quot;,
            ]
          + display_name      = &amp;quot;UDP_NETMEMO-NETBIOS&amp;quot;
          + protocol          = &amp;quot;UDP&amp;quot;
          + source_ports      = []
        }
    }

Plan: 5 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + grp = {
      + NETMEMO-ESX   = {
          + conjunction       = []
          + criteria          = [
              + {
                  + condition             = [
                      + {
                          + key         = &amp;quot;Tag&amp;quot;
                          + member_type = &amp;quot;VirtualMachine&amp;quot;
                          + operator    = &amp;quot;EQUALS&amp;quot;
                          + value       = &amp;quot;ESX&amp;quot;
                        },
                      + {
                          + key         = &amp;quot;Tag&amp;quot;
                          + member_type = &amp;quot;VirtualMachine&amp;quot;
                          + operator    = &amp;quot;EQUALS&amp;quot;
                          + value       = &amp;quot;VMWARE&amp;quot;
                        },
                    ]
                  + ipaddress_expression  = []
                  + macaddress_expression = []
                  + path_expression       = []
                },
            ]
          + description       = null
          + display_name      = &amp;quot;NETMEMO-ESX&amp;quot;
          + domain            = &amp;quot;default&amp;quot;
          + extended_criteria = []
          + id                = (known after apply)
          + nsx_id            = (known after apply)
          + path              = (known after apply)
          + revision          = (known after apply)
          + tag               = []
        }
      + NETMEMO-LOCAL = {
          + conjunction       = []
          + criteria          = [
              + {
                  + condition             = []
                  + ipaddress_expression  = [
                      + {
                          + ip_addresses = [
                              + &amp;quot;10.0.0.0/25&amp;quot;,
                              + &amp;quot;10.1.1.0/25&amp;quot;,
                            ]
                        },
                    ]
                  + macaddress_expression = []
                  + path_expression       = []
                },
            ]
          + description       = null
          + display_name      = &amp;quot;NETMEMO-LOCAL&amp;quot;
          + domain            = &amp;quot;default&amp;quot;
          + extended_criteria = []
          + id                = (known after apply)
          + nsx_id            = (known after apply)
          + path              = (known after apply)
          + revision          = (known after apply)
          + tag               = []
        }
      + NETMEMO-NAS   = {
          + conjunction       = []
          + criteria          = [
              + {
                  + condition             = [
                      + {
                          + key         = &amp;quot;Tag&amp;quot;
                          + member_type = &amp;quot;VirtualMachine&amp;quot;
                          + operator    = &amp;quot;EQUALS&amp;quot;
                          + value       = &amp;quot;NAS&amp;quot;
                        },
                      + {
                          + key         = &amp;quot;Tag&amp;quot;
                          + member_type = &amp;quot;VirtualMachine&amp;quot;
                          + operator    = &amp;quot;EQUALS&amp;quot;
                          + value       = &amp;quot;FILES&amp;quot;
                        },
                    ]
                  + ipaddress_expression  = []
                  + macaddress_expression = []
                  + path_expression       = []
                },
            ]
          + description       = null
          + display_name      = &amp;quot;NETMEMO-NAS&amp;quot;
          + domain            = &amp;quot;default&amp;quot;
          + extended_criteria = []
          + id                = (known after apply)
          + nsx_id            = (known after apply)
          + path              = (known after apply)
          + revision          = (known after apply)
          + tag               = []
        }
    }
  + svc = {
      + NETMEMO-ESP     = {
          + algorithm_entry   = []
          + description       = null
          + display_name      = &amp;quot;NETMEMO-ESP&amp;quot;
          + ether_type_entry  = []
          + icmp_entry        = []
          + id                = (known after apply)
          + igmp_entry        = []
          + ip_protocol_entry = [
              + {
                  + description  = &amp;quot;&amp;quot;
                  + display_name = &amp;quot;&amp;quot;
                  + protocol     = 50
                },
            ]
          + l4_port_set_entry = []
          + nsx_id            = (known after apply)
          + path              = (known after apply)
          + revision          = (known after apply)
          + tag               = []
        }
      + NETMEMO-NETBIOS = {
          + algorithm_entry   = []
          + description       = null
          + display_name      = &amp;quot;NETMEMO-NETBIOS&amp;quot;
          + ether_type_entry  = []
          + icmp_entry        = []
          + id                = (known after apply)
          + igmp_entry        = []
          + ip_protocol_entry = []
          + l4_port_set_entry = [
              + {
                  + description       = &amp;quot;&amp;quot;
                  + destination_ports = [
                      + &amp;quot;135&amp;quot;,
                      + &amp;quot;137&amp;quot;,
                      + &amp;quot;139&amp;quot;,
                    ]
                  + display_name      = &amp;quot;TCP_NETMEMO-NETBIOS&amp;quot;
                  + protocol          = &amp;quot;TCP&amp;quot;
                  + source_ports      = []
                },
              + {
                  + description       = &amp;quot;&amp;quot;
                  + destination_ports = [
                      + &amp;quot;135&amp;quot;,
                      + &amp;quot;137&amp;quot;,
                      + &amp;quot;139&amp;quot;,
                    ]
                  + display_name      = &amp;quot;UDP_NETMEMO-NETBIOS&amp;quot;
                  + protocol          = &amp;quot;UDP&amp;quot;
                  + source_ports      = []
                },
            ]
          + nsx_id            = (known after apply)
          + path              = (known after apply)
          + revision          = (known after apply)
          + tag               = []
        }
    }

──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Saved the plan to: plan.out
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;terraform apply plan.out&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module.nsxt-tf-cm-svc.nsxt_policy_service.svc[&amp;quot;NETMEMO-NETBIOS&amp;quot;]: Creating...
module.nsxt-tf-cm-grp.nsxt_policy_group.grp[&amp;quot;NETMEMO-NAS&amp;quot;]: Creating...
module.nsxt-tf-cm-grp.nsxt_policy_group.grp[&amp;quot;NETMEMO-LOCAL&amp;quot;]: Creating...
module.nsxt-tf-cm-grp.nsxt_policy_group.grp[&amp;quot;NETMEMO-ESX&amp;quot;]: Creating...
module.nsxt-tf-cm-svc.nsxt_policy_service.svc[&amp;quot;NETMEMO-ESP&amp;quot;]: Creating...
module.nsxt-tf-cm-svc.nsxt_policy_service.svc[&amp;quot;NETMEMO-ESP&amp;quot;]: Creation complete after 0s [id=434fdc00-30e6-4072-a64b-a7e9534c80c2]
module.nsxt-tf-cm-svc.nsxt_policy_service.svc[&amp;quot;NETMEMO-NETBIOS&amp;quot;]: Creation complete after 0s [id=59a29e53-9901-44d2-9589-f770c36d87bb]
module.nsxt-tf-cm-grp.nsxt_policy_group.grp[&amp;quot;NETMEMO-ESX&amp;quot;]: Creation complete after 0s [id=0fb48626-d903-42cc-9513-b47e7626f44d]
module.nsxt-tf-cm-grp.nsxt_policy_group.grp[&amp;quot;NETMEMO-LOCAL&amp;quot;]: Creation complete after 0s [id=21d93fff-c08c-42dd-90da-d099dfa51163]
module.nsxt-tf-cm-grp.nsxt_policy_group.grp[&amp;quot;NETMEMO-NAS&amp;quot;]: Creation complete after 0s [id=bac7f9c7-d80c-4bfe-8663-d3c9f973e2fb]

Apply complete! Resources: 5 added, 0 changed, 0 destroyed.
...

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;6.Create the policies and rules&lt;/summary&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;terraform plan -out plan.out&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following
symbols:
  + create

Terraform will perform the following actions:

  # module.nsxt-tf-cm-dfw.nsxt_policy_security_policy.policies[&amp;quot;NETMEMO-POL1&amp;quot;] will be created
  + resource &amp;quot;nsxt_policy_security_policy&amp;quot; &amp;quot;policies&amp;quot; {
      + category        = &amp;quot;Application&amp;quot;
      + display_name    = &amp;quot;NETMEMO-POL1&amp;quot;
      + domain          = &amp;quot;default&amp;quot;
      + id              = (known after apply)
      + locked          = false
      + nsx_id          = (known after apply)
      + path            = (known after apply)
      + revision        = (known after apply)
      + sequence_number = 10
      + stateful        = true
      + tcp_strict      = (known after apply)

      + rule {
          + action                = &amp;quot;ALLOW&amp;quot;
          + destination_groups    = [
              + &amp;quot;/infra/domains/default/groups/bac7f9c7-d80c-4bfe-8663-d3c9f973e2fb&amp;quot;,
            ]
          + destinations_excluded = false
          + direction             = &amp;quot;IN_OUT&amp;quot;
          + disabled              = false
          + display_name          = &amp;quot;NETMEMO-NAS-R&amp;quot;
          + ip_version            = &amp;quot;IPV4_IPV6&amp;quot;
          + logged                = false
          + nsx_id                = (known after apply)
          + revision              = (known after apply)
          + rule_id               = (known after apply)
          + scope                 = [
              + &amp;quot;/infra/domains/default/groups/bac7f9c7-d80c-4bfe-8663-d3c9f973e2fb&amp;quot;,
            ]
          + sequence_number       = (known after apply)
          + services              = [
              + &amp;quot;/infra/services/HTTPS&amp;quot;,
            ]
          + source_groups         = [
              + &amp;quot;/infra/domains/default/groups/bac7f9c7-d80c-4bfe-8663-d3c9f973e2fb&amp;quot;,
            ]
          + sources_excluded      = false
        }
      + rule {
          + action                = &amp;quot;ALLOW&amp;quot;
          + destination_groups    = [
              + &amp;quot;/infra/domains/default/groups/0fb48626-d903-42cc-9513-b47e7626f44d&amp;quot;,
            ]
          + destinations_excluded = false
          + direction             = &amp;quot;IN_OUT&amp;quot;
          + disabled              = false
          + display_name          = &amp;quot;NETMEMO-ESX-R&amp;quot;
          + ip_version            = &amp;quot;IPV4_IPV6&amp;quot;
          + logged                = false
          + nsx_id                = (known after apply)
          + revision              = (known after apply)
          + rule_id               = (known after apply)
          + scope                 = [
              + &amp;quot;/infra/domains/default/groups/0fb48626-d903-42cc-9513-b47e7626f44d&amp;quot;,
            ]
          + sequence_number       = (known after apply)
          + services              = [
              + &amp;quot;/infra/services/HTTPS&amp;quot;,
            ]
          + source_groups         = [
              + &amp;quot;/infra/domains/default/groups/0fb48626-d903-42cc-9513-b47e7626f44d&amp;quot;,
            ]
          + sources_excluded      = false
        }
    }

  # module.nsxt-tf-cm-dfw.nsxt_policy_security_policy.policies[&amp;quot;NETMEMO-POL2&amp;quot;] will be created
  + resource &amp;quot;nsxt_policy_security_policy&amp;quot; &amp;quot;policies&amp;quot; {
      + category        = &amp;quot;Application&amp;quot;
      + display_name    = &amp;quot;NETMEMO-POL2&amp;quot;
      + domain          = &amp;quot;default&amp;quot;
      + id              = (known after apply)
      + locked          = false
      + nsx_id          = (known after apply)
      + path            = (known after apply)
      + revision        = (known after apply)
      + sequence_number = 20
      + stateful        = true
      + tcp_strict      = (known after apply)

      + rule {
          + action                = &amp;quot;ALLOW&amp;quot;
          + destination_groups    = [
              + &amp;quot;/infra/domains/default/groups/0fb48626-d903-42cc-9513-b47e7626f44d&amp;quot;,
              + &amp;quot;/infra/domains/default/groups/bac7f9c7-d80c-4bfe-8663-d3c9f973e2fb&amp;quot;,
            ]
          + destinations_excluded = false
          + direction             = &amp;quot;IN_OUT&amp;quot;
          + disabled              = false
          + display_name          = &amp;quot;NETMEMO-LOCAL-R&amp;quot;
          + ip_version            = &amp;quot;IPV4_IPV6&amp;quot;
          + logged                = false
          + nsx_id                = (known after apply)
          + revision              = (known after apply)
          + rule_id               = (known after apply)
          + scope                 = [
              + &amp;quot;/infra/domains/default/groups/0fb48626-d903-42cc-9513-b47e7626f44d&amp;quot;,
              + &amp;quot;/infra/domains/default/groups/bac7f9c7-d80c-4bfe-8663-d3c9f973e2fb&amp;quot;,
            ]
          + sequence_number       = (known after apply)
          + services              = [
              + &amp;quot;/infra/services/59a29e53-9901-44d2-9589-f770c36d87bb&amp;quot;,
              + &amp;quot;/infra/services/HTTPS&amp;quot;,
            ]
          + source_groups         = [
              + &amp;quot;/infra/domains/default/groups/21d93fff-c08c-42dd-90da-d099dfa51163&amp;quot;,
            ]
          + sources_excluded      = false
        }
    }

Plan: 2 to add, 0 to change, 0 to destroy.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;terraform apply plan.out&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;module.nsxt-tf-cm-dfw.nsxt_policy_security_policy.policies[&amp;quot;NETMEMO-POL1&amp;quot;]: Creating...
module.nsxt-tf-cm-dfw.nsxt_policy_security_policy.policies[&amp;quot;NETMEMO-POL2&amp;quot;]: Creating...
module.nsxt-tf-cm-dfw.nsxt_policy_security_policy.policies[&amp;quot;NETMEMO-POL2&amp;quot;]: Creation complete after 1s [id=bab4c14e-30c6-4633-b9d7-db760844e0e7]
module.nsxt-tf-cm-dfw.nsxt_policy_security_policy.policies[&amp;quot;NETMEMO-POL1&amp;quot;]: Creation complete after 1s [id=867b5893-15e3-4dab-a2f0-c8084af790a7]

Apply complete! Resources: 2 added, 0 changed, 0 destroyed.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;7.Check the result through the UI&lt;/summary&gt;
&lt;a href=&#34;nsx-services.png&#34;&gt; &lt;img src=&#34;nsx-services.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;nsx-groups.png&#34;&gt; &lt;img src=&#34;nsx-groups.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;nsx-dfw.png&#34;&gt; &lt;img src=&#34;nsx-dfw.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;br /&gt;
&lt;/details&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Subnet sizing and heterogeneous subnets</title>
      <link>https://netmemo.github.io/post/subnets-size-mix/</link>
      <pubDate>Tue, 18 May 2021 22:28:39 +0200</pubDate>
      
      <guid>https://netmemo.github.io/post/subnets-size-mix/</guid>
      <description>

&lt;p&gt;Along my different jobs, one of the things that led to L2 extension and then brought risks and slew down or even blocked projects was big heterogeneous subnets.&lt;/p&gt;

&lt;p&gt;Often the initial rational of big heterogeneous subnets was to avoid too much vlans on physical infrastructure. Historically physical infrastructure had vlans and spanning tree limits.
The problem is that when migration time is coming nobody wants to change IP addresses. Even after arguing, this is the network that bears the risk to break the entire company by stretching L2. No need to say that the layer 2 extension stay forever because it takes ages to migrate everything. After two years, there is no more budget for the dozen of remaining devices and everybody move on leting the network as a battled field.
Some people are even arguing that with microsementation you only need one vlan&amp;hellip;&lt;/p&gt;

&lt;p&gt;In this blog I will list the pros and cons of small, big and heterogeneous subnets.&lt;/p&gt;

&lt;h1 id=&#34;small-subnet&#34;&gt;Small subnet&lt;/h1&gt;

&lt;p&gt;I like to think of using small subnets as a &amp;ldquo;scale out&amp;rdquo; approach. When the subnet is full you just assign a new subnet in the same reserved space.&lt;/p&gt;

&lt;h2 id=&#34;pros&#34;&gt;Pros&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Agility. You can do &lt;a href=&#34;https://blog.ipspace.net/2020/12/50-shades-high-availability.html&#34;&gt;swimlane&lt;/a&gt; application design. When migration time is coming, you can do it per application.&lt;/li&gt;
&lt;li&gt;For application migration, if you can&amp;rsquo;t change the ip addresses of the servers, you can reroute the trafic without jeorpadizing the entire company with L2 extension.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;cons&#34;&gt;Cons&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;More entries in the routing table but that can be mitigated with summarization.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Loss of ip addresses. Does it really matter ? how full are the big subnets ?&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;big-subnet&#34;&gt;Big subnet&lt;/h1&gt;

&lt;p&gt;This is for me a more &amp;ldquo;scale up&amp;rdquo; approach. You oversize subnets then when you need a new server, you pick one IP in the big subnet without asking any question.&lt;/p&gt;

&lt;h2 id=&#34;pros-1&#34;&gt;Pros&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;IP address saving. Is it worth it ? Most of the time the subnets are big only to anticipate growth and those IPs are lost anyway.&lt;/li&gt;
&lt;li&gt;Simplicity to allocate addresses. Only a couple of big subnets.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;cons-1&#34;&gt;Cons&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;If the subnet is not full, it&amp;rsquo;s very difficult to carve out the unused space in the subnet to use it somewhere else.&lt;/li&gt;
&lt;li&gt;L2 broadcast domain is mitigated by arp suppression on modern fabric but still you have broadcast reaching every VM and thus can have troubles if the &lt;a href=&#34;http://yves-louis.com/DCI/wp-content/uploads/2015/10/VXLAN-Multipod-geographically-dispersed-white-paper-final.pdf&#34;&gt;stormcontrol is not set properly&lt;/a&gt;.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;For all the firewalls in the enterprise that are not relying on tags, you might have to open firewall rules per host instead of per subnets.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;heterogeneous-subnet&#34;&gt;Heterogeneous subnet&lt;/h1&gt;

&lt;p&gt;It&amp;rsquo;s not rare to see big subnets also heterogeneous with a mix of applications and workload type (physical/virtual).&lt;/p&gt;

&lt;h2 id=&#34;pros-2&#34;&gt;Pros&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;It allows physical devices like NAS or Loadbalancer to be in the same subnet as your application workloads (If you want to avoid putting a FW in between and can&amp;rsquo;t use VRF mechanism)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;cons-2&#34;&gt;Cons&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Application mutualization. It can block applications migration because not all the applications have the same requirements. If one of the application has been asked to migrate somewhere else and nobody wants to change IP addresses, you might be forced to stretch L2.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Mix of workload type (physical/virtual). It can block applications migration because the physical devices can&amp;rsquo;t go where the VMs are going. If nobody wants to change IP addresses, you might be forced to stretch L2.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;other-considerations&#34;&gt;Other considerations&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Pets vs cattle : VM vs Container&lt;br /&gt;
In the above use cases I&amp;rsquo;m talking essentially of workloads that are not containers. For containers the paradigm is often different because most of the time containers don&amp;rsquo;t share the subnet with physical device and application developper doesn&amp;rsquo;t rely on the containers IP addresses. What matter is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Fully_qualified_domain_name&#34;&gt;FQDN&lt;/a&gt; of the service. VM are still considered most of the time as pets and nobody wants to change the IP address mostly to avoid to change firewall rules or hard coded IP addresses in application.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;VLANs Scale&lt;br /&gt;
The number of supported VLAN are less relevent in virtualized environments because most of the time software scale better and you are not limited to 4K vlans (or even 2K in some case for ACI &lt;a href=&#34;https://www.cisco.com/c/en/us/td/docs/switches/datacenter/aci/apic/sw/4-x/verified-scalability/Cisco-ACI-Verified-Scalability-Guide-422.html&#34;&gt;Bridge Domain&lt;/a&gt; and EVPN &lt;a href=&#34;https://www.cisco.com/c/en/us/td/docs/switches/datacenter/nexus9000/sw/92x/scalability/guide_923/b_Cisco_Nexus_9000_Series_NX-OS_Verified_Scalability_Guide_923.html&#34;&gt;Layer 2 VNIs&lt;/a&gt;).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Suboptimal IP addressing plan&lt;br /&gt;
When you move an entire subnet somewhere else you can break the summarization of the company but you can always do the summarization again after all the applications have moved or even reIP the entire subnet afterwards. It&amp;rsquo;s less risky and complex than having a L2 streched &amp;ldquo;forever&amp;rdquo;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Distributed routing&lt;br /&gt;
Now, with distributed routing you don&amp;rsquo;t have to go to the network core where the default gateway was in the old days to route between subnets. The trafic have a better distribution in the fabric and you should have less risks to congest uplinks with EAST/WEST trafic.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Terraform Refactoring State File</title>
      <link>https://netmemo.github.io/post/terraform-refactoring-state-file/</link>
      <pubDate>Thu, 25 Feb 2021 21:56:57 +0100</pubDate>
      
      <guid>https://netmemo.github.io/post/terraform-refactoring-state-file/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.terraform.io/docs/cli/commands/state/mv.html&#34;&gt;https://www.terraform.io/docs/cli/commands/state/mv.html&lt;/a&gt;&lt;br /&gt;
On windows :&lt;br /&gt;
&lt;pre style=&#34;color:black&#34;&gt;
terraform state mv nsxt_policy_security_policy.policy1 nsxt_policy_security_policy.policies[\&amp;ldquo;policy1\&amp;ldquo;]
&lt;/pre&gt;
It move resources from a construct like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;locals {
  policy1= {
      rule1 = {
        source = [&amp;quot;src1&amp;quot;,&amp;quot;src2&amp;quot;]
      }
  }
  policy2 = {
      rule1 = {
        source = [&amp;quot;src3&amp;quot;,&amp;quot;src4&amp;quot;]
      }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To a structure like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;locals {
  policies = {
    policy1 = {
      rule1 = {
        source = [&amp;quot;src1&amp;quot;,&amp;quot;src2&amp;quot;]
      }
    }
    policy2 = {
      rule2 = {
        source = [&amp;quot;src3&amp;quot;,&amp;quot;src4&amp;quot;]
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The main moving from&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;nsxt_policy_security_policy&amp;quot; &amp;quot;policy1&amp;quot;{
  display_name = &amp;quot;policy1&amp;quot;
  category     = &amp;quot;Environment&amp;quot;
  dynamic &amp;quot;rule&amp;quot; {
    for_each = local.policy1
    content {
      source_groups = rule.value[&amp;quot;sources&amp;quot;]
    }
  }
}
resource &amp;quot;nsxt_policy_security_policy&amp;quot; &amp;quot;policy2&amp;quot;{
  display_name = &amp;quot;policy2&amp;quot;
  category     = &amp;quot;Environment&amp;quot;
  dynamic &amp;quot;rule&amp;quot; {
    for_each = local.policy2
    content {
      source_groups = rule.value[&amp;quot;sources&amp;quot;]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;nsxt_policy_security_policy&amp;quot; &amp;quot;policies&amp;quot; {
for_each = local.policies
  display_name = each.key
  category     = &amp;quot;Environment&amp;quot;
  dynamic &amp;quot;rule&amp;quot; {
    for_each = each.value
    content {
      source_groups = rule.value[&amp;quot;sources&amp;quot;]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The terraform state moving fromfrom 2 resources to 1 resource with 2 instances&lt;br /&gt;
From&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;type&amp;quot;: &amp;quot;nsxt_policy_security_policy&amp;quot;,
  &amp;quot;name&amp;quot;: &amp;quot;policy1&amp;quot;
  &amp;quot;instances&amp;quot; : [
    {
      ...
    }
  ]
},
{
  &amp;quot;type&amp;quot;: &amp;quot;nsxt_policy_security_policy&amp;quot;,
  &amp;quot;name&amp;quot;: &amp;quot;policy2&amp;quot;
  &amp;quot;instances&amp;quot; : [
    {
      ...
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;type&amp;quot;: &amp;quot;nsxt_policy_security_policy&amp;quot;,
  &amp;quot;name&amp;quot;: &amp;quot;policies&amp;quot;
  &amp;quot;instances&amp;quot; : [
    {
      &amp;quot;index_key&amp;quot;: &amp;quot;policy1&amp;quot;
    },
    {
      &amp;quot;index_key&amp;quot;: &amp;quot;policy2&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Python Package Offline</title>
      <link>https://netmemo.github.io/post/python-package-offline/</link>
      <pubDate>Thu, 25 Feb 2021 21:46:14 +0100</pubDate>
      
      <guid>https://netmemo.github.io/post/python-package-offline/</guid>
      <description>&lt;p&gt;To install python packages offline (with no internet access), the simplest way is to dowload the packages with the dependencies on a server with internet access and the below command.&lt;/p&gt;

&lt;pre&gt;
&lt;b&gt;C:\Users\Nono\Desktop\python&gt;pip download requests&lt;/b&gt;
Collecting requests  
  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)  
Collecting urllib3&lt;1.27,&gt;=1.21.1  
  Using cached urllib3-1.26.3-py2.py3-none-any.whl (137 kB)  
Collecting certifi&gt;=2017.4.17  
  Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB)  
Collecting idna&lt;3,&gt;=2.5  
  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)  
Collecting chardet&lt;5,&gt;=3.0.2  
  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)  
Saved c:\users\nono\desktop\python\requests-2.25.1-py2.py3-none-any.whl  
Saved c:\users\nono\desktop\python\certifi-2020.12.5-py2.py3-none-any.whl  
Saved c:\users\nono\desktop\python\chardet-4.0.0-py2.py3-none-any.whl  
Saved c:\users\nono\desktop\python\idna-2.10-py2.py3-none-any.whl  
Saved c:\users\nono\desktop\python\urllib3-1.26.3-py2.py3-none-any.whl  
Successfully downloaded requests certifi chardet idna urllib3
&lt;/pre&gt;

&lt;p&gt;You then need to move all the files to the offline server in a directory and deploy the packages with the below command :&lt;/p&gt;

&lt;pre&gt;
&lt;b&gt;pip install --no-index --find-links=file:C:\Users\Nono2\tools\python-modules\resquests requests&lt;/b&gt;
Looking in links: file:///C:\Users\Nono2\tools\python-modules\resquests  
Collecting requestsCollecting urllib3&lt;1.27,&gt;=1.21.1 (from requests)  
Collecting chardet&lt;5,&gt;=3.0.2 (from requests)  
Collecting idna&lt;3,&gt;=2.5 (from requests)Collecting certifi&gt;=2017.4.17 (from requests)  
Installing collected package: urllib3, chardet, idna, certifi, requests  
Successfully installed certifi-2020.12.5 chardet-4.0.0 idna-2.10 requests-2.25.1 urllib3-1.26.3
&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>N5600 Buffering</title>
      <link>https://netmemo.github.io/post/n5600-buffering/</link>
      <pubDate>Tue, 23 Feb 2021 22:24:44 +0100</pubDate>
      
      <guid>https://netmemo.github.io/post/n5600-buffering/</guid>
      <description>

&lt;h4 id=&#34;qos-voq&#34;&gt;QoS VOQ&lt;/h4&gt;

&lt;p&gt;On N5K, In the case of unicast traffic, VOQ is an ingress buffer pool for 3 ingress ports (1 ASIC = 3 ports). This buffer pool is split into n x reservable buffer of the size configured in the voq-limit command. If the ingress buffer is 16000 and the VOQ limit is 1024, that mean 16 flow can reserv buffers. When the shared buffer is exausted, the dedicated ingress buffer per port is used then when it&amp;rsquo;s full, the packet is droped.&lt;/p&gt;

&lt;p&gt;VOQ is reservable per egress port per class (pair).&lt;br /&gt;
With small VOQ limit, there is lot of buffer available for non congested flow.&lt;br /&gt;
With no VOQ limit, a congested port can use up to 50% of the total shared memory and those, 2 congested port can exaust all the ingress resources of an ASIC (3 ingress port) and drop can happen on this ASIC&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.ciscolive.com/c/dam/r/ciscolive/us/docs/2015/pdf/BRKDCT-3100.pdf&#34;&gt;https://www.ciscolive.com/c/dam/r/ciscolive/us/docs/2015/pdf/BRKDCT-3100.pdf&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.ciscolive.com/c/dam/r/ciscolive/us/docs/2017/pdf/BRKDCN-3346.pdf&#34;&gt;https://www.ciscolive.com/c/dam/r/ciscolive/us/docs/2017/pdf/BRKDCN-3346.pdf&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.cisco.com/c/en/us/support/docs/switches/nexus-6000-series-switches/200401-Nexus-5600-6000-Understanding-and-Troub.html&#34;&gt;https://www.cisco.com/c/en/us/support/docs/switches/nexus-6000-series-switches/200401-Nexus-5600-6000-Understanding-and-Troub.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In case of a Nexus 5600. 1 ASIC = 3 * 40Gb or 12*10G ports. Cells are the units in which buffers are allocated. One cell is 320 Bytes. ASIC Ingress buffer size : 48840 of available total cells (16M), shared among all 3x40Gb ports. Egress buffer is 9Mb (dedicated buffer per ASIC).&lt;br /&gt;
VOQ = Ingress per output port/class queues. E.g with 114 ports on the switch, with 8 queues per port there would be 1152 VOQs. On N5600 Buffer can be shared accrod port and classes, giving more burst absorption capacity.&lt;/p&gt;

&lt;h4 id=&#34;default-buffer-allocation&#34;&gt;Default buffer allocation&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;minimum fixed buffer of 312 cells (100KB) is reserved per class (up to 8 classes) per ingress port, rest of the buffer is shared. This is done to guarantee minimum performance.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If there is only 1 class (the class-default for instance), there is only a single fixed/dedicated buffer per port.&lt;br /&gt;
- 44,331 cells of shared buffer available for data traffic for all ports. shared buffer is used first.&lt;br /&gt;
- any drop class can access half of the shared buffer- no-drop class (eg fcoe) can access complete shared buffer.&lt;br /&gt;
- &amp;ldquo;queue-limit&amp;rdquo; under &amp;ldquo;network-qos&amp;rdquo; policy specifies the dedicated buffer for each port and each class. The dedicated buffer can be used by the port for only that class of service.&lt;/p&gt;

&lt;h4 id=&#34;voq-limit&#34;&gt;voq-limit&lt;/h4&gt;

&lt;p&gt;Command &amp;ldquo;hardware unicast voq-limit [threshold &amp;hellip;]&amp;rdquo;
enabling voq-limit turns on a shared buffer threshold per each voq.&lt;br /&gt;
limits the amount of buffers usable on the ingress interface, for packets headed towards a specific VoQ (&amp;ldquo;egress port, class&amp;rdquo; pair). Drops happens per VOQ, when its packet in ingress buffer exceed threshold: when the traffic ingress on a port and it consumes all 1024 cells, it will get dropped as discards.&lt;/p&gt;

&lt;p&gt;when the second flow traffic comes in, it will tage another 1024 cells as well but in a different VOQ and will not get dropped; this way voq thresholding prevents the non-congested egress port traffic drop.&lt;/p&gt;

&lt;h4 id=&#34;hold-mitigation-and-voq-thresholding&#34;&gt;HOLD mitigation and VOQ thresholding&lt;/h4&gt;

&lt;p&gt;Below is discussed for scenario without voq-limit enabledCongestion on one egress port in one CoS eventually bleeds into the congestion of its corresponding VOQ on the ingress port. Once the limit is reached then traffic gets dropped.&lt;/p&gt;

&lt;p&gt;On N5600 ASIC Buffers are allocated per ingress port and are shared by all the egress ports that are seeing traffic from this ingressport.&lt;br /&gt;
A stuck or slow-draining egress port can causse all buffers on one or more ingress ports that are senfing traffic to the egress port to be exhausted, thereby affecting all traffic on these ingress port. This is Head of Line Blocking (HOLB) problem.&lt;br /&gt;
To avoid this scenario, the VOQ for unicast traffic may be configured with a voq-limit threshold, at which point the port will stop accepting any more packets for congested destination (drops the packets or pauses the affected class for non-drop class type). When the queue length decrease and goes below another threshold, the VOQ starts accepting packets again.&lt;br /&gt;
By default VOQ Thresholding is disabled for all classes.&lt;/p&gt;

&lt;h4 id=&#34;questions&#34;&gt;Questions&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;About the limit of 8000 cells, why not setting directly 16000 or removeing the limitation ?&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Setting larger voq-limit increases the change to improve burst absorption but also leaves non-congested VOQs to be more likely affected by congested VOQs (as the latter can dip more into shared buffer).Disadvantage of having a voq-limit is that when we have a burst traffic comming in (like for distributed storage/VSAN), it connot use more than configured threshold of allocated cells and the bursty flow will have drops even though there is un-used ingress buffer.It&amp;rsquo;s recommanded to remove voq-limit in case of bursty traffic.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Are the VoQ per UPC or per ingress interface ?&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;VOQs are per class per egress interface. E.g. With 114 ports on the switch with 8 queues there would be 1152 VOQs per port.If there is only 1 class (class-defauklt), the number of VOQ is matching the number of egress ports.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Our undestanding is that if we remove the command voq limit, we might have HOLB while with the command it&amp;rsquo;s not possible. Could you explain how is this possible to have HOLD if VoQ is always used ?&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This can happen because VOQ Thresholding (voq-limit) is not enabled by default. Therefore, each VOQ can borrow from shared buffer and some of non-congested VOQs would not be able to handle traffic due to lack of buffer space, even though they are not congested.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Effect of changing or removing VOQ-limit on the traffic.&lt;br /&gt;
There would be subsecond traffic interruption on all ports.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Effect of changing or removing VOQ-Limit on the FEX.&lt;br /&gt;
There should not be any effect on the FEX operation&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Could you describe the difference in the behavior of buffers (shared, ingress dedicated per port, voq per cos, drop) with the command voq limit default, with the command voq limit configured with the max value, and without the voq limit command ?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A. Without voq-limitShared - used by all ingress ports by default. 3*40G (or) 12*10G ports compete for usage, when per-port buffers are exhausted.Dedicated - samll, reserved per port per class. Can be adjusted with queue-limit command.VOQ drop thresholds are disabled.Shared is used first, only then overflow to dedicated.One drop class per ASIC can take up to half if the shared buffer.If congestion is constant, it can result in blocking for other VOQs in the same ingress port.Slow draining port can affect others by consuming shared and dedicated buffers.ExempleUnicast traffic coming on a 40G ingress port and egress port are 2x10G. When one of the egress port 10G is congested, it moght be possible that a new ingress flow from this 40G interface to another 10G interface can get affected as well because of non-availability of the ingress buffer.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;n5600-buffering.png&#34; alt=&#34;N5600 Buffers&#34; /&gt;&lt;/p&gt;

&lt;p&gt;When the traffic ingress on a port it first fills the shared buffer. Each flow can take up ti 50% of the total shared buffer available (22200 cells or ~7.1MB). After filling 50% of the buffer the same flow will utilize the per-port fixed buffer.When the new flow comes ingress on that port, it tries to fill in the 50% of shared buffer but if shared and per-port buffer are already filled, this traffic would be dropped.We can avoir the new flow, that is goignt o different no-congested port, from getting dropped by enabling VOQ thresholding.&lt;/p&gt;

&lt;p&gt;B. With voq-limit default value 1024Drop happend per VOQ, each limited by 1024 cells.Congestion in one VOQ has minimal chances to affect other VOQsVOQ drop thresholds are minimal, so burst traffic flow coming in it cannot use more than 1024 allocated cells and will have drops even though there is un-used buffer.when the traffic ingress on a port consumes all 1024 cells, it will get dropped as discards.When the second flow traffic with destination to another egress port comes in, it may consume 1024 cells as well but a different VOQ- so will not get dropped.&lt;/p&gt;

&lt;p&gt;C. with voq-limit default value 16384drop happens per VOQ, each limited by 16384 cells.congestion in one VOQ does not affect other VOQs if there is enough shared buffer left.VOQ drop thresholds are at maximum.Burst traffic flow coming can use up to 16384 allocated cells and will have drop everything above it. Other VOQs buffering at the same instance can use remaining buffer (but nor more than 16384each). In theory, 3 VOQs, that are fully congested at the same time, could take all the buffer. It is very difficult to prefict instant buffer usage due to unpredictable nature of bursty flows, so exact values should be taken from production, e.g. Try with 16384 and reduce the threshold if negative impact is seen on non-congested flows.&lt;/p&gt;

&lt;h4 id=&#34;couple-of-solutions-to-resolve-bursty-trafic-drop&#34;&gt;Couple of solutions to resolve bursty trafic drop:&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;Remove VOQ limit completel (heavy burst trafic)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Increase VOQ Threshold to 8000 or 16384 (max) and monitor the situation with discards=&amp;gt; show hardware profile buffer monitor interface ethernet&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Spread congested links betweek different ASICs.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Implement policing of the traffic.&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Terraform nested for_each for NSX-T with dynamic</title>
      <link>https://netmemo.github.io/post/tf-nsxt-nested-for-each/</link>
      <pubDate>Fri, 19 Feb 2021 22:06:50 +0100</pubDate>
      
      <guid>https://netmemo.github.io/post/tf-nsxt-nested-for-each/</guid>
      <description>&lt;p&gt;The post below shows how to create security policy groups for NSX-T with Terraform nested for_each loop and dynamic.&lt;br /&gt;
The variables are made from one map of list. Each list represents one group composed of tags.&lt;br /&gt;
&lt;a href=&#34;https://www.hashicorp.com/blog/hashicorp-terraform-0-12-preview-for-and-for-each&#34;&gt;https://www.hashicorp.com/blog/hashicorp-terraform-0-12-preview-for-and-for-each&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;variable &amp;quot;mapgroups&amp;quot; {
  type		= map
  default	= {
    NBO			= [&amp;quot;NBO&amp;quot;]
    NBO-PROD	= [&amp;quot;NBO&amp;quot;,&amp;quot;PROD&amp;quot;]
  }
}


resource &amp;quot;nsxt_policy_group&amp;quot; &amp;quot;nbogroups&amp;quot; {
  for_each		= var.mapgroups

  display_name	= each.key
  criteria {

    dynamic &amp;quot;condition&amp;quot; {
      for_each = each.value

      content {
        key			= &amp;quot;Tag&amp;quot;
        member_type	= &amp;quot;VirtualMachine&amp;quot;
        operator	= &amp;quot;EQUALS&amp;quot;
        value		= condition.value
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Create portable Terraform and plugins with Terraform-bundle for Windows</title>
      <link>https://netmemo.github.io/post/tf-bundle-windows/</link>
      <pubDate>Wed, 17 Feb 2021 21:32:37 +0100</pubDate>
      
      <guid>https://netmemo.github.io/post/tf-bundle-windows/</guid>
      <description>

&lt;p&gt;The steps below are what I have followed to create a terraform-bundle to use terraform with non default providers on a server that doesn&amp;rsquo;t have access to Internet. You can find the tool explanation in the below link.&lt;br /&gt;
&lt;a href=&#34;https://github.com/hashicorp/terraform/tree/master/tools/terraform-bundle&#34;&gt;https://github.com/hashicorp/terraform/tree/master/tools/terraform-bundle&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;installation of golang with msi downloaded here&lt;br /&gt;
&lt;a href=&#34;https://golang.org/doc/install&#34;&gt;https://golang.org/doc/install&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Clone the terraform repository to get the tool&lt;br /&gt;
&lt;a href=&#34;https://github.com/hashicorp/terraform.git&#34;&gt;https://github.com/hashicorp/terraform.git&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd terraform-master
go install .\tools\terraform-bundle
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;check-the-terraform-version&#34;&gt;Check the terraform version&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;C:\Users\noyel\Desktop\tfforeach\nsxt&amp;gt;terraform version
Terraform v0.14.6
+ provider registry.terraform.io/vmware/nsxt v3.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;create-a-terraform-bundle-hcl-file&#34;&gt;Create a terraform-bundle.hcl file&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;terraform {
  # Version of Terraform to include in the bundle. An exact version number
  # is required.
  version = &amp;quot;0.14.6&amp;quot;
}

# Define which provider plugins are to be included
providers {
  # Include the newest &amp;quot;nsxt&amp;quot; provider version in the 1.0 series.
  nsxt = {
    source = &amp;quot;vmware/nsxt&amp;quot;
    versions = [&amp;quot;~&amp;gt; 3.0.0&amp;quot;]
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;create-the-bundle&#34;&gt;Create the bundle&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;C:\Users\noyel\Desktop\tfforeach\nsxt&amp;gt;terraform-bundle package terraform-bundle.hcl
Fetching Terraform 0.14.6 core package...
Local plugin directory &amp;quot;.plugins&amp;quot; found; scanning for provider binaries.
No &amp;quot;.plugins&amp;quot; directory found, skipping local provider discovery.
- Finding vmware/nsxt versions matching &amp;quot;~&amp;gt; 3.0.0&amp;quot;...
- Installing vmware/nsxt v3.0.1...
Creating terraform_0.14.6-bundle2021021713_windows_amd64.zip ...
All done!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Move the zip file to the server you want to use. Unzip the file. For a basic utilization move the terraform.exe and plugins in the directory where your terraform files are.&lt;/p&gt;

&lt;h4 id=&#34;the-provider-tf-file-looks&#34;&gt;The provider.tf file looks&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;terraform {
  required_providers {
    nsxt = {
      source = &amp;quot;vmware/nsxt&amp;quot;
      version = &amp;quot;3.0.1&amp;quot;
    }
  }
}

provider &amp;quot;nsxt&amp;quot; {
   host = &amp;quot;1.2.3.4&amp;quot;
   username   = &amp;quot;admin&amp;quot;
   password   = &amp;quot;123&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When initialize Terraform with the init command, specify the plugins directory.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;C:\Users\bubibi\terraform\terraform init -plugin-dir=C:\Users\bubibi\terraform\plugins

Terraform has been successfuly initialized!
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
